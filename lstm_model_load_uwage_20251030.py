# -*- coding: utf-8 -*-
"""
Title   : LSTM ì˜ˆì¸¡ - ê°œì„ ëœ ì—­ì •ê·œí™” ë°©ì‹
Author  : ì£¼ì„±ì¤‘ / (ì£¼)ë§µì¸ì–´ìŠ¤
Description: 
    - âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë…ë¦½ì ì¸ ì—­ì •ê·œí™” ë°©ì‹
    - âœ… ì „ì²´ í”¼ì²˜ ë²¡í„°ë¥¼ í™œìš©í•œ ì•ˆì „í•œ ë³€í™˜
    - âœ… StandardScaler, MinMaxScaler ë“± ëª¨ë‘ ì§€ì›
Version : 9.0 (ì—­ì •ê·œí™” ê°œì„ )
Date    : 2025-10-28
"""

import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
import json
import joblib
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta

ENV = os.getenv('FLASK_ENV', 'local')
if ENV == 'local':
    root = "D:/work/lstm"
else:
    root = "/app/webfiles/lstm"

model_path = os.path.abspath(root + "/saved_models")
prediction_path = os.path.abspath(root + "/predictions")
os.makedirs(prediction_path, exist_ok=True)

def get_db_engine():
    connection_string = "postgresql://postgres:mapinus@10.10.10.201:5432/postgres"
    return create_engine(connection_string)

def convert_to_serializable(obj):
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, pd.Timestamp):
        return obj.isoformat()
    elif isinstance(obj, datetime):
        return obj.isoformat()
    return obj

def load_new_data(tablename, dateColumn, studyColumns):
    try:
        engine = get_db_engine()
        
        query = f"""
            SELECT {studyColumns},{dateColumn}
            FROM carbontwin.{tablename}
            WHERE {dateColumn} IS NOT NULL
            ORDER BY {dateColumn} ASC
            """
        
        data = pd.read_sql_query(query, engine)
        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(data)}í–‰")
        
        if len(data) > 0 and dateColumn in data.columns:
            data[dateColumn] = pd.to_datetime(data[dateColumn])
            min_date = data[dateColumn].min()
            max_date = data[dateColumn].max()
            print(f"   ğŸ“… ê¸°ê°„: {min_date} ~ {max_date}")
        
        return data
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

def load_trained_model(model_name):
    try:
        model_file = os.path.join(model_path, f"{model_name}.h5")
        scaler_file = os.path.join(model_path, f"{model_name}_scaler.pkl")
        config_file = os.path.join(model_path, f"{model_name}_config.json")
        
        if not all(os.path.exists(f) for f in [model_file, scaler_file, config_file]):
            print(f"âŒ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None
        
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ: {model_name}")
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            model = load_model(model_file, compile=False)
            model.compile(optimizer='adam', loss='mse')
            scaler = joblib.load(scaler_file)
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   - íƒ€ê²Ÿ: {config['targetColumn']}")
        print(f"   - ì‹œí€€ìŠ¤: {config['r_seqLen']}")
        print(f"   - ìŠ¤ì¼€ì¼ëŸ¬: {type(scaler).__name__}")
        
        return model, scaler, config
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None, None, None

def validate_with_actual_data(model, scaler, config, data, validation_days=7):
    """ê²€ì¦ í•¨ìˆ˜ - ê°œì„ ëœ ì—­ì •ê·œí™” ë°©ì‹"""
    try:
        print(f"\n{'='*80}")
        print(f"ğŸ” ëª¨ë¸ ê²€ì¦ ì‹œì‘ (ìµœê·¼ {validation_days}ì¼)")
        print(f"{'='*80}")
        
        dateColumn = config['dateColumn']
        studyColumns = config['studyColumns']
        targetColumn = config['targetColumn']
        seq_len = int(config['r_seqLen'])
        r_predDays = int(config.get('r_predDays', 1))
        
        study_columns_list = [col.strip() for col in studyColumns.split(',')]
        target_idx = study_columns_list.index(targetColumn)
        
        data_for_prediction = data[study_columns_list].astype(float)
        dates = pd.to_datetime(data[dateColumn])
        
        validation_points = 96 * validation_days
        validation_start_idx = len(data) - validation_points - r_predDays
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            data_scaled = scaler.transform(data_for_prediction)
        
        testX, testY = [], []
        test_range = range(seq_len, len(data_scaled) - r_predDays + 1)
        
        for i in test_range:
            if i < validation_start_idx:
                continue
            testX.append(data_scaled[i - seq_len:i, :].astype(np.float32))
            testY.append(data_scaled[i + r_predDays - 1:i + r_predDays, target_idx].astype(np.float32))
        
        testX = np.array(testX, dtype=np.float32)
        testY = np.array(testY, dtype=np.float32)
        
        print(f"\nğŸ”„ ì—­ì •ê·œí™” ë°©ì‹: ì „ì²´ í”¼ì²˜ ë²¡í„° í™œìš© (ìŠ¤ì¼€ì¼ëŸ¬ ë…ë¦½ì )")
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            prediction = model.predict(testX, verbose=0)
            
            # âœ… ê°œì„ ëœ ì—­ì •ê·œí™”: ì „ì²´ í”¼ì²˜ ë²¡í„° ë°©ì‹
            # ì˜ˆì¸¡ê°’ ì—­ì •ê·œí™”
            y_pred = []
            for i, pred_scaled in enumerate(prediction):
                # testX[i]ì˜ ë§ˆì§€ë§‰ ìŠ¤í…ì„ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©
                full_scaled = testX[i, -1, :].copy()  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì „ì²´ í”¼ì²˜
                full_scaled[target_idx] = pred_scaled[0]  # íƒ€ê²Ÿ ìœ„ì¹˜ì— ì˜ˆì¸¡ê°’ ì‚½ì…
                full_original = scaler.inverse_transform(full_scaled.reshape(1, -1))[0]
                y_pred.append(full_original[target_idx])
            y_pred = np.array(y_pred)
            
            # ì‹¤ì œê°’ ì—­ì •ê·œí™”
            testY_original = []
            for i, y_scaled in enumerate(testY):
                full_scaled = testX[i, -1, :].copy()  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì „ì²´ í”¼ì²˜
                full_scaled[target_idx] = y_scaled[0]  # íƒ€ê²Ÿ ìœ„ì¹˜ì— ì‹¤ì œê°’ ì‚½ì…
                full_original = scaler.inverse_transform(full_scaled.reshape(1, -1))[0]
                testY_original.append(full_original[target_idx])
            testY_original = np.array(testY_original)
        
        eps = 9
        mask = testY_original > eps
        mape = np.mean(np.abs((y_pred[mask] - testY_original[mask]) / testY_original[mask])) * 100 if np.sum(mask) > 0 else 999.0
        
        accuracy = 100 - mape
        mae = np.mean(np.abs(y_pred - testY_original))
        rmse = np.sqrt(np.mean((y_pred - testY_original) ** 2))
        
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   ì •í™•ë„: {accuracy:.2f}%")
        print(f"   MAPE:   {mape:.2f}%")
        print(f"   MAE:    {mae:.4f}")
        print(f"   RMSE:   {rmse:.4f}")
        
        return {
            "status": "success",
            "statistics": {"accuracy": accuracy, "mape": mape, "mae": mae, "rmse": rmse},
            "historical_mean": np.mean(testY_original),
            "historical_std": np.std(testY_original)
        }
        
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def predict_future_stable(model, scaler, config, data, future_steps=672, historical_mean=None, historical_std=None):
    """
    LSTM ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¯¸ë˜ ì „ë ¥ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ í•¨ìˆ˜
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ë°ì´í„°ì—ì„œ í‰ì¼/íœ´ì¼ íŒ¨í„´ ìë™ í•™ìŠµ
    2. ìš”ì¼ë³„ ë§ì¶¤í˜• ì•ˆì •í™” ì ìš©
    3. ì „ì²´ í”¼ì²˜ ë²¡í„° ë°©ì‹ì˜ ì•ˆì „í•œ ì—­ì •ê·œí™”
    4. ì‹œê°„ íŠ¹ì„± ìë™ ì—…ë°ì´íŠ¸
    
    Args:
        model: í•™ìŠµëœ LSTM ëª¨ë¸
        scaler: ë°ì´í„° ì •ê·œí™”ì— ì‚¬ìš©ëœ ìŠ¤ì¼€ì¼ëŸ¬ (StandardScaler, MinMaxScaler ë“±)
        config: ëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì‹œí€€ìŠ¤ ê¸¸ì´, ì»¬ëŸ¼ ì •ë³´ ë“±)
        data: ê³¼ê±° ë°ì´í„° DataFrame
        future_steps: ì˜ˆì¸¡í•  ë¯¸ë˜ ìŠ¤í… ìˆ˜ (ê¸°ë³¸ê°’: 672 = 7ì¼ Ã— 96ê°œ/ì¼)
        historical_mean: ê³¼ê±° í‰ê· ê°’ (Noneì´ë©´ ìë™ ê³„ì‚°)
        historical_std: ê³¼ê±° í‘œì¤€í¸ì°¨ (Noneì´ë©´ ìë™ ê³„ì‚°)
    
    Returns:
        dict: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
            - metadata: ëª¨ë¸ ì •ë³´, ì˜ˆì¸¡ ë°©ë²• ë“±
            - predictions: ë‚ ì§œë³„ ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
            - statistics: ì˜ˆì¸¡ í†µê³„ (ìµœì†Œ, ìµœëŒ€, í‰ê· , í‘œì¤€í¸ì°¨)
    
    ì „ì œ ì¡°ê±´:
        - í† ìš”ì¼, ì¼ìš”ì¼ = íœ´ì¼ (ìƒì‚° ê±°ì˜ ì—†ìŒ)
        - ì›”~ê¸ˆ = í‰ì¼ (ì •ìƒ ìƒì‚°)
        - ì‹œê°„ëŒ€ë³„ íŠ¹ì„± ì—†ìŒ (ìš”ì¼ë§Œ ì¤‘ìš”)
    """
    
    def calculate_workday_holiday_patterns(data_for_prediction, dates, targetColumn):
        """
        ê³¼ê±° ë°ì´í„°ì—ì„œ í‰ì¼/íœ´ì¼ íŒ¨í„´ì„ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” í•¨ìˆ˜
        
        ì´ í•¨ìˆ˜ëŠ” ê³¼ê±° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬:
        1. í‰ì¼(ì›”~ê¸ˆ)ê³¼ íœ´ì¼(í† ~ì¼)ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¦¬
        2. ê° ê·¸ë£¹ì˜ í†µê³„ì  íŠ¹ì„± ê³„ì‚° (í‰ê· , í‘œì¤€í¸ì°¨, ë¶„ìœ„ìˆ˜ ë“±)
        3. ìš”ì¼ë³„ ìƒì„¸ ì •ë³´ë„ í•¨ê»˜ ê³„ì‚°
        
        Args:
            data_for_prediction: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°ì´í„° DataFrame
            dates: ë‚ ì§œ ì •ë³´ê°€ ë‹´ê¸´ Series
            targetColumn: ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼ëª… (ì˜ˆ: 'usage_kwh')
        
        Returns:
            tuple: (patterns, weekday_details)
                - patterns: í‰ì¼/íœ´ì¼ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
                - weekday_details: ìš”ì¼ë³„ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        print(f"   ğŸ” í‰ì¼/íœ´ì¼ íŒ¨í„´ í•™ìŠµ ì¤‘...")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì˜ ê°’ë“¤ì„ numpy ë°°ì—´ë¡œ ì¶”ì¶œ
        target_values = data_for_prediction[targetColumn].values
        
        # í‰ì¼ (ì›”~ê¸ˆ) vs íœ´ì¼ (í† , ì¼) ë¶„ë¦¬
        # weekday(): 0=ì›”ìš”ì¼, 1=í™”ìš”ì¼, ..., 4=ê¸ˆìš”ì¼, 5=í† ìš”ì¼, 6=ì¼ìš”ì¼
        weekday_mask = dates.dt.weekday < 5  # 0~4 = ì›”~ê¸ˆ (True/False ë°°ì—´)
        weekend_mask = dates.dt.weekday >= 5  # 5~6 = í† ~ì¼ (True/False ë°°ì—´)
        
        # ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ë¦¬
        weekday_values = target_values[weekday_mask]  # í‰ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
        weekend_values = target_values[weekend_mask]  # íœ´ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
        
        # í‰ì¼/íœ´ì¼ ê°ê°ì˜ í†µê³„ì  íŠ¹ì„± ê³„ì‚°
        patterns = {
            "workday": {  # í‰ì¼ íŒ¨í„´
                "mean": float(np.mean(weekday_values)),      # í‰ê· 
                "std": float(np.std(weekday_values)),        # í‘œì¤€í¸ì°¨
                "median": float(np.median(weekday_values)),  # ì¤‘ì•™ê°’
                "min": float(np.min(weekday_values)),        # ìµœì†Œê°’
                "max": float(np.max(weekday_values)),        # ìµœëŒ€ê°’
                "q25": float(np.percentile(weekday_values, 25)),  # 1ì‚¬ë¶„ìœ„ìˆ˜ (25%)
                "q75": float(np.percentile(weekday_values, 75)),  # 3ì‚¬ë¶„ìœ„ìˆ˜ (75%)
                "zero_ratio": float(np.sum(weekday_values == 0) / len(weekday_values)),  # 0ê°’ ë¹„ìœ¨
                "count": len(weekday_values)  # ë°ì´í„° ê°œìˆ˜
            },
            "holiday": {  # íœ´ì¼ íŒ¨í„´
                "mean": float(np.mean(weekend_values)),
                "std": float(np.std(weekend_values)),
                "median": float(np.median(weekend_values)),
                "min": float(np.min(weekend_values)),
                "max": float(np.max(weekend_values)),
                "q25": float(np.percentile(weekend_values, 25)),
                "q75": float(np.percentile(weekend_values, 75)),
                "zero_ratio": float(np.sum(weekend_values == 0) / len(weekend_values)),
                "count": len(weekend_values)
            }
        }
        
        # ê° ìš”ì¼ë³„ ìƒì„¸ ì •ë³´ë„ ì¶”ê°€ë¡œ ê³„ì‚° (ì¶œë ¥ ë° ë¶„ì„ìš©)
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        weekday_details = {}
        
        for day_idx in range(7):  # 0~6 = ì›”~ì¼
            # íŠ¹ì • ìš”ì¼ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œ
            day_mask = dates.dt.weekday == day_idx
            day_values = target_values[day_mask]
            
            if len(day_values) > 0:  # í•´ë‹¹ ìš”ì¼ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                weekday_details[day_idx] = {
                    "name": weekday_names[day_idx],  # ìš”ì¼ ì´ë¦„
                    "mean": float(np.mean(day_values)),  # í‰ê· 
                    "std": float(np.std(day_values)),    # í‘œì¤€í¸ì°¨
                    "zero_ratio": float(np.sum(day_values == 0) / len(day_values)),  # 0ê°’ ë¹„ìœ¨
                    "count": len(day_values),  # ë°ì´í„° ê°œìˆ˜
                    "is_workday": day_idx < 5  # í‰ì¼ ì—¬ë¶€ (ì›”~ê¸ˆ = True)
                }
        
        return patterns, weekday_details
    
    def adaptive_stabilization(pred_original, next_date, patterns):
        """
        ì˜ˆì¸¡ê°’ì„ í‰ì¼/íœ´ì¼ íŒ¨í„´ì— ë§ê²Œ ì•ˆì •í™”í•˜ëŠ” í•¨ìˆ˜
        
        ì´ í•¨ìˆ˜ëŠ”:
        1. ì˜ˆì¸¡ ë‚ ì§œê°€ í‰ì¼ì¸ì§€ íœ´ì¼ì¸ì§€ íŒë‹¨
        2. í•´ë‹¹ íŒ¨í„´ì˜ í†µê³„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ê°’ ì•ˆì •í™”
        3. í‰ì¼: í‰ê·  íšŒê·€ + 3Ïƒ ë²”ìœ„ ì œí•œ
        4. íœ´ì¼: ì—„ê²©í•œ ìƒí•œ ì œí•œ (ìƒì‚° ê±°ì˜ ì—†ìŒ)
        
        Args:
            pred_original: ëª¨ë¸ì˜ ì›ë˜ ì˜ˆì¸¡ê°’
            next_date: ì˜ˆì¸¡ ë‚ ì§œ (datetime)
            patterns: í‰ì¼/íœ´ì¼ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
        
        Returns:
            tuple: (ì•ˆì •í™”ëœ ì˜ˆì¸¡ê°’, ì•ˆì •í™” ì—¬ë¶€, ì‚¬ìœ , ìš”ì¼ëª…, íƒ€ì…, ì•„ì´ì½˜)
        """
        # ì˜ˆì¸¡ ë‚ ì§œì˜ ìš”ì¼ í™•ì¸ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
        day_of_week = next_date.weekday()
        
        # í‰ì¼ ì—¬ë¶€ íŒë‹¨ (ì›”~ê¸ˆ = True)
        is_workday = day_of_week < 5
        
        # íŒ¨í„´ ì„ íƒ (í‰ì¼ ë˜ëŠ” íœ´ì¼)
        if is_workday:
            pattern = patterns["workday"]  # í‰ì¼ íŒ¨í„´ ì‚¬ìš©
            day_type = "í‰ì¼"
            icon = "ğŸ¢"
        else:
            pattern = patterns["holiday"]  # íœ´ì¼ íŒ¨í„´ ì‚¬ìš©
            day_type = "íœ´ì¼"
            icon = "ğŸ–ï¸"
        
        # ìš”ì¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        weekday_name = weekday_names[day_of_week]
        
        # íŒ¨í„´ì˜ í†µê³„ê°’ ì¶”ì¶œ
        mean = pattern["mean"]      # í‰ê· 
        std = pattern["std"]        # í‘œì¤€í¸ì°¨
        q25 = pattern["q25"]        # 1ì‚¬ë¶„ìœ„ìˆ˜
        q75 = pattern["q75"]        # 3ì‚¬ë¶„ìœ„ìˆ˜
        min_val = pattern["min"]    # ìµœì†Œê°’
        max_val = pattern["max"]    # ìµœëŒ€ê°’
        
        # ì•ˆì •í™” ì¶”ì  ë³€ìˆ˜
        original_pred = pred_original  # ì›ë³¸ ì˜ˆì¸¡ê°’ ì €ì¥
        stabilization_applied = False  # ì•ˆì •í™” ì ìš© ì—¬ë¶€
        stabilization_reason = ""      # ì•ˆì •í™” ì‚¬ìœ 
        
        # ====================================================================
        # í‰ì¼ ì•ˆì •í™” ë¡œì§
        # ====================================================================
        if is_workday:  # í‰ì¼ (ì›”~ê¸ˆ)
            # 1ë‹¨ê³„: í‰ê·  íšŒê·€ (Mean Reversion)
            # ì˜ˆì¸¡ê°’ì´ í‰ê· ì—ì„œ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ í‰ê· ìª½ìœ¼ë¡œ ë‹¹ê¹€
            deviation = abs(pred_original - mean)  # í‰ê· ê³¼ì˜ ê±°ë¦¬
            threshold = 2.5 * std  # ì„ê³„ê°’: 2.5 í‘œì¤€í¸ì°¨
            
            if deviation > threshold:
                # í‰ê· ê³¼ ì˜ˆì¸¡ê°’ì˜ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë³´ì •
                # alpha=0.6 â†’ í‰ê· ì— 60%, ì˜ˆì¸¡ê°’ì— 40% ê°€ì¤‘ì¹˜
                alpha = 0.6
                pred_original = alpha * mean + (1 - alpha) * pred_original
                stabilization_applied = True
                stabilization_reason = f"í‰ì¼ í‰ê·  íšŒê·€ (í¸ì°¨: {deviation:.1f})"
            
            # 2ë‹¨ê³„: ê·¹ë‹¨ê°’ ì œí•œ (3Ïƒ ë²”ìœ„)
            # ì˜ˆì¸¡ê°’ì´ ì •ìƒ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ê°•ì œë¡œ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
            safe_min = max(0, mean - 3 * std)  # í•˜í•œ: í‰ê·  - 3í‘œì¤€í¸ì°¨ (ìŒìˆ˜ ë°©ì§€)
            safe_max = min(max_val, mean + 3 * std)  # ìƒí•œ: í‰ê·  + 3í‘œì¤€í¸ì°¨ (ìµœëŒ€ê°’ ì´ˆê³¼ ë°©ì§€)
            
            # í•˜í•œ ì²´í¬
            if pred_original < safe_min:
                pred_original = safe_min
                if not stabilization_applied:
                    stabilization_applied = True
                    stabilization_reason = "í‰ì¼ ìµœì†Œê°’ ì œí•œ"
            
            # ìƒí•œ ì²´í¬
            elif pred_original > safe_max:
                pred_original = safe_max
                if not stabilization_applied:
                    stabilization_applied = True
                    stabilization_reason = "í‰ì¼ ìµœëŒ€ê°’ ì œí•œ"
        
        # ====================================================================
        # íœ´ì¼ ì•ˆì •í™” ë¡œì§
        # ====================================================================
        else:  # íœ´ì¼ (í† , ì¼)
            # íœ´ì¼ì€ ìƒì‚°ì´ ê±°ì˜ ì—†ìœ¼ë¯€ë¡œ ì—„ê²©í•œ ì œí•œ ì ìš©
            
            # 1ë‹¨ê³„: ìƒí•œ ì œí•œ (í‰ê·  + 2í‘œì¤€í¸ì°¨)
            upper_limit = mean + 2 * std  # í‰ì¼ë³´ë‹¤ ì—„ê²©í•œ ê¸°ì¤€ (2Ïƒ vs 3Ïƒ)
            
            if pred_original > upper_limit:
                # IQR(Interquartile Range) ë²”ìœ„ë¡œ ì œí•œ
                # IQR = Q3 - Q1, ì´ìƒì¹˜ íƒì§€ì— ì‚¬ìš©ë˜ëŠ” í†µê³„ì  ë²”ìœ„
                pred_original = np.clip(pred_original, min_val, q75)
                stabilization_applied = True
                stabilization_reason = f"íœ´ì¼ ì œí•œ (ìƒí•œ: {upper_limit:.1f})"
            
            # 2ë‹¨ê³„: ê·¹ë‹¨ê°’ ì–µì œ
            # ì˜ˆì¸¡ê°’ì´ í‰ê· ì˜ 3ë°°ë¥¼ ë„˜ìœ¼ë©´ í™•ë¥ ì ìœ¼ë¡œ ë‚®ì€ ê°’ìœ¼ë¡œ ëŒ€ì²´
            if pred_original > mean * 3:
                # ìµœì†Œê°’ê³¼ í‰ê· *1.5 ì‚¬ì´ì˜ ëœë¤ê°’ìœ¼ë¡œ ëŒ€ì²´
                pred_original = np.random.uniform(min_val, mean * 1.5)
                stabilization_applied = True
                stabilization_reason = "íœ´ì¼ ê·¹ë‹¨ê°’ ì–µì œ"
        
        # ====================================================================
        # ìµœì¢… ì•ˆì „ ë²”ìœ„
        # ====================================================================
        # ìŒìˆ˜ ë°©ì§€ (ì „ë ¥ ì‚¬ìš©ëŸ‰ì€ ìŒìˆ˜ê°€ ë  ìˆ˜ ì—†ìŒ)
        pred_original = max(0, pred_original)
        
        return pred_original, stabilization_applied, stabilization_reason, weekday_name, day_type, icon
    
    def update_time_features(next_row, next_date, study_columns_list):
        """
        ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ ì‹œ ì‹œê°„ ê´€ë ¨ íŠ¹ì„±ì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
        
        ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë³€í•˜ëŠ” íŠ¹ì„±ë“¤ì„ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸:
        - week_code: ìš”ì¼ ì½”ë“œ (1~6)
        - is_weekend: ì£¼ë§ ì—¬ë¶€ (0 ë˜ëŠ” 1)
        - is_workday: í‰ì¼ ì—¬ë¶€ (0 ë˜ëŠ” 1)
        - day_sin, day_cos: ìš”ì¼ ìˆœí™˜ ì¸ì½”ë”©
        
        Args:
            next_row: ì—…ë°ì´íŠ¸í•  ë°ì´í„° í–‰ (numpy array)
            next_date: ë‹¤ìŒ ì˜ˆì¸¡ ë‚ ì§œ (datetime)
            study_columns_list: íŠ¹ì„± ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            numpy.ndarray: ì‹œê°„ íŠ¹ì„±ì´ ì—…ë°ì´íŠ¸ëœ ë°ì´í„° í–‰
        """
        # ì˜ˆì¸¡ ë‚ ì§œì˜ ìš”ì¼ í™•ì¸ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
        day_of_week = next_date.weekday()
        
        # ====================================================================
        # 1. week_code ì—…ë°ì´íŠ¸
        # ====================================================================
        # week_code: ìš”ì¼ì„ ìˆ«ìë¡œ í‘œí˜„ (ì›”=1, í™”=2, ..., í† =6, ì¼=6)
        # ì£¼ë§(í† , ì¼)ì€ ëª¨ë‘ 6ìœ¼ë¡œ ì²˜ë¦¬
        if 'week_code' in study_columns_list:
            idx = study_columns_list.index('week_code')
            # day_of_week: 0(ì›”)~6(ì¼) â†’ +1í•˜ë©´ 1~7
            # min(..., 6)ìœ¼ë¡œ ì¼ìš”ì¼(7)ë„ 6ìœ¼ë¡œ ì œí•œ
            next_row[idx] = min(day_of_week + 1, 6)
        
        # ====================================================================
        # 2. is_weekend ì—…ë°ì´íŠ¸
        # ====================================================================
        # is_weekend: ì£¼ë§(í† , ì¼) ì—¬ë¶€ë¥¼ ì´ì§„ê°’ìœ¼ë¡œ í‘œí˜„
        # í† ìš”ì¼(5), ì¼ìš”ì¼(6) = 1, ê·¸ ì™¸ = 0
        if 'is_weekend' in study_columns_list:
            idx = study_columns_list.index('is_weekend')
            next_row[idx] = 1 if day_of_week >= 5 else 0
        
        # ====================================================================
        # 3. is_workday ì—…ë°ì´íŠ¸
        # ====================================================================
        # is_workday: í‰ì¼(ì›”~ê¸ˆ) ì—¬ë¶€ë¥¼ ì´ì§„ê°’ìœ¼ë¡œ í‘œí˜„
        # ì›”~ê¸ˆ = 1, í† ~ì¼ = 0
        # ì£¼ì˜: ì‹œê°„ëŒ€ ë¬´ê´€! (ìš”ì¼ë§Œìœ¼ë¡œ íŒë‹¨)
        if 'is_workday' in study_columns_list:
            idx = study_columns_list.index('is_workday')
            next_row[idx] = 1 if day_of_week < 5 else 0
        
        # ====================================================================
        # 4. ìˆœí™˜ ì¸ì½”ë”© (Cyclic Encoding) - ìš”ì¼
        # ====================================================================
        # ìš”ì¼ì„ sin/cosë¡œ ì¸ì½”ë”©í•˜ì—¬ ì—°ì†ì„± í‘œí˜„
        # ì˜ˆ: ì¼ìš”ì¼(6)ê³¼ ì›”ìš”ì¼(0)ì´ ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‘œí˜„
        
        # day_sin: sin(2Ï€ Ã— ìš”ì¼ / 7)
        # ì›”(0)â†’0.00, í™”(1)â†’0.78, ìˆ˜(2)â†’0.97, ..., ì¼(6)â†’-0.43
        if 'day_sin' in study_columns_list:
            idx = study_columns_list.index('day_sin')
            next_row[idx] = np.sin(2 * np.pi * day_of_week / 7)
        
        # day_cos: cos(2Ï€ Ã— ìš”ì¼ / 7)
        # ì›”(0)â†’1.00, í™”(1)â†’0.62, ìˆ˜(2)â†’-0.22, ..., ì¼(6)â†’0.90
        if 'day_cos' in study_columns_list:
            idx = study_columns_list.index('day_cos')
            next_row[idx] = np.cos(2 * np.pi * day_of_week / 7)
        
        # ìˆœí™˜ ì¸ì½”ë”©ì˜ ì¥ì :
        # - ì¼ìš”ì¼(6)ê³¼ ì›”ìš”ì¼(0)ì˜ ê±°ë¦¬ê°€ 1ë¡œ í‘œí˜„ë¨
        # - ì„ í˜• ì¸ì½”ë”©(0,1,2,...,6)ë³´ë‹¤ ìš”ì¼ ê°„ ì—°ì†ì„±ì„ ë” ì˜ í‘œí˜„
        
        return next_row
    
    # ====================================================================
    # ë©”ì¸ ì˜ˆì¸¡ ë¡œì§ ì‹œì‘
    # ====================================================================
    
    try:
        print(f"\n{'='*80}")
        print(f"ğŸ”® í‰ì¼/íœ´ì¼ ê¸°ë°˜ ì˜ˆì¸¡ ({future_steps}ê°œ ìŠ¤í… = {future_steps//96}ì¼)")
        print(f"{'='*80}")
        
        # ====================================================================
        # 1ë‹¨ê³„: ì„¤ì • ì •ë³´ ì¶”ì¶œ
        # ====================================================================
        dateColumn = config['dateColumn']        # ë‚ ì§œ ì»¬ëŸ¼ëª… (ì˜ˆ: 'time_point')
        studyColumns = config['studyColumns']    # íŠ¹ì„± ì»¬ëŸ¼ë“¤ (CSV ë¬¸ìì—´)
        targetColumn = config['targetColumn']    # ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼ (ì˜ˆ: 'usage_kwh')
        seq_len = int(config['r_seqLen'])       # ì‹œí€€ìŠ¤ ê¸¸ì´ (ì˜ˆ: 672)
        r_predDays = int(config.get('r_predDays', 1))  # ì˜ˆì¸¡ ìŠ¤í… (ê¸°ë³¸ê°’: 1)
        
        # íŠ¹ì„± ì»¬ëŸ¼ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        # ì˜ˆ: "is_workday,week_code,usage_kwh" â†’ ['is_workday', 'week_code', 'usage_kwh']
        study_columns_list = [col.strip() for col in studyColumns.split(',')]
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        # ì˜ˆ: 'usage_kwh'ê°€ 3ë²ˆì§¸ ì»¬ëŸ¼ì´ë©´ target_idx = 2 (0ë¶€í„° ì‹œì‘)
        target_idx = study_columns_list.index(targetColumn)
        
        # ====================================================================
        # 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„
        # ====================================================================
        # ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°ì´í„°ë§Œ ì¶”ì¶œ (íŠ¹ì„± ì»¬ëŸ¼ë“¤ë§Œ)
        data_for_prediction = data[study_columns_list].astype(float)
        
        # ë‚ ì§œ ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        dates = pd.to_datetime(data[dateColumn])
        
        # ë§ˆì§€ë§‰ ë‚ ì§œ ì €ì¥ (ì˜ˆì¸¡ ì‹œì‘ì )
        last_date = dates.iloc[-1]
        
        # ====================================================================
        # 3ë‹¨ê³„: í‰ì¼/íœ´ì¼ íŒ¨í„´ ìë™ í•™ìŠµ
        # ====================================================================
        # ê³¼ê±° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í‰ì¼/íœ´ì¼ì˜ í†µê³„ì  íŠ¹ì„± ì¶”ì¶œ
        patterns, weekday_details = calculate_workday_holiday_patterns(
            data_for_prediction, dates, targetColumn
        )
        
        # í‰ê· /í‘œì¤€í¸ì°¨ ê¸°ë³¸ê°’ ì„¤ì •
        # íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë°ì´í„°ì˜ í‰ê· /í‘œì¤€í¸ì°¨ ì‚¬ìš©
        if historical_mean is None:
            historical_mean = data_for_prediction[targetColumn].mean()
        if historical_std is None:
            historical_std = data_for_prediction[targetColumn].std()
        
        # ====================================================================
        # í•™ìŠµëœ íŒ¨í„´ ì¶œë ¥
        # ====================================================================
        print(f"\n   ğŸ“Š í•™ìŠµëœ íŒ¨í„´:")
        
        # í‰ì¼ íŒ¨í„´ ì¶œë ¥
        print(f"      ğŸ¢ í‰ì¼ (ì›”~ê¸ˆ):")
        print(f"         - í‰ê· : {patterns['workday']['mean']:6.2f} kWh (Â±{patterns['workday']['std']:5.2f})")
        print(f"         - ë²”ìœ„: [{patterns['workday']['min']:.2f}, {patterns['workday']['max']:.2f}]")
        print(f"         - 0ê°’ ë¹„ìœ¨: {patterns['workday']['zero_ratio']*100:4.1f}%")
        print(f"         - ë°ì´í„° ìˆ˜: {patterns['workday']['count']:,}ê°œ")
        
        # íœ´ì¼ íŒ¨í„´ ì¶œë ¥
        print(f"\n      ğŸ–ï¸ íœ´ì¼ (í† , ì¼):")
        print(f"         - í‰ê· : {patterns['holiday']['mean']:6.2f} kWh (Â±{patterns['holiday']['std']:5.2f})")
        print(f"         - ë²”ìœ„: [{patterns['holiday']['min']:.2f}, {patterns['holiday']['max']:.2f}]")
        print(f"         - 0ê°’ ë¹„ìœ¨: {patterns['holiday']['zero_ratio']*100:4.1f}%")
        print(f"         - ë°ì´í„° ìˆ˜: {patterns['holiday']['count']:,}ê°œ")
        
        # ìš”ì¼ë³„ ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"\n   ğŸ“… ìš”ì¼ë³„ ìƒì„¸:")
        for day_idx in range(7):
            if day_idx in weekday_details:
                detail = weekday_details[day_idx]
                icon = "ğŸ¢" if detail["is_workday"] else "ğŸ–ï¸"
                print(f"      {icon} {detail['name']}ìš”ì¼: {detail['mean']:6.2f} kWh "
                      f"(Â±{detail['std']:5.2f}) | 0ê°’: {detail['zero_ratio']*100:4.1f}%")
        
        print(f"\n   ğŸ”„ ì—­ì •ê·œí™”: ì „ì²´ í”¼ì²˜ ë²¡í„° ë°©ì‹")
        
        # ====================================================================
        # 4ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”
        # ====================================================================
        # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë°ì´í„° ì •ê·œí™”
        # ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ì„¤ì •
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            data_scaled = scaler.transform(data_for_prediction)
        
        # ====================================================================
        # 5ë‹¨ê³„: ì´ˆê¸° ì‹œí€€ìŠ¤ ì¤€ë¹„
        # ====================================================================
        # ë§ˆì§€ë§‰ seq_lenê°œ ë°ì´í„°ë¥¼ ì´ˆê¸° ì‹œí€€ìŠ¤ë¡œ ì‚¬ìš©
        # ì˜ˆ: seq_len=672ì´ë©´ ë§ˆì§€ë§‰ 672ê°œ ë°ì´í„° (7ì¼ì¹˜)
        current_sequence = data_scaled[-seq_len:, :].copy()
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
        future_predictions = []  # ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
        future_dates = []        # ì˜ˆì¸¡ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
        stabilization_log = []   # ì•ˆì •í™” ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        max_log = 10             # ìµœëŒ€ ë¡œê·¸ ê°œìˆ˜
        
        # ====================================================================
        # 6ë‹¨ê³„: ì˜ˆì¸¡ ë£¨í”„ (í•µì‹¬ ë¡œì§)
        # ====================================================================
        # future_stepsë²ˆ ë°˜ë³µí•˜ì—¬ ë¯¸ë˜ ì˜ˆì¸¡
        # ê° ìŠ¤í…ë§ˆë‹¤: ì˜ˆì¸¡ â†’ ì•ˆì •í™” â†’ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
        for step in range(future_steps):
            # ================================================================
            # 6-1. ëª¨ë¸ ì˜ˆì¸¡ (ì •ê·œí™” ê³µê°„)
            # ================================================================
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                # í˜„ì¬ ì‹œí€€ìŠ¤ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
                # shape: (1, seq_len, num_features)
                # 1: ë°°ì¹˜ í¬ê¸°, seq_len: ì‹œí€€ìŠ¤ ê¸¸ì´, num_features: íŠ¹ì„± ê°œìˆ˜
                X = current_sequence.reshape(1, seq_len, -1)
                
                # LSTM ëª¨ë¸ë¡œ ì˜ˆì¸¡ (ì •ê·œí™”ëœ ê³µê°„ì—ì„œ)
                # ì¶œë ¥: (1, 1) í˜•íƒœ â†’ [0, 0]ìœ¼ë¡œ ìŠ¤ì¹¼ë¼ ê°’ ì¶”ì¶œ
                pred_scaled = model.predict(X, verbose=0)[0, 0]
                
                # ============================================================
                # 6-2. ì—­ì •ê·œí™” (ì „ì²´ í”¼ì²˜ ë²¡í„° ë°©ì‹)
                # ============================================================
                # ìŠ¤ì¼€ì¼ëŸ¬ ì¢…ë¥˜ì— ë¬´ê´€í•œ ì•ˆì „í•œ ì—­ì •ê·œí™” ë°©ë²•
                
                # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì „ì²´ íŠ¹ì„± ë²¡í„° ë³µì‚¬
                # shape: (num_features,)
                full_scaled = current_sequence[-1].copy()
                
                # íƒ€ê²Ÿ ìœ„ì¹˜ì—ë§Œ ì˜ˆì¸¡ê°’ ì‚½ì…
                # ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                full_scaled[target_idx] = pred_scaled
                
                # ì „ì²´ ë²¡í„°ë¥¼ ì—­ì •ê·œí™”
                # shape: (1, num_features) â†’ (num_features,)
                full_original = scaler.inverse_transform(full_scaled.reshape(1, -1))[0]
                
                # íƒ€ê²Ÿ ê°’ë§Œ ì¶”ì¶œ
                pred_original = float(full_original[target_idx])
                
                # ì™œ ì´ ë°©ì‹ì„ ì‚¬ìš©í•˜ë‚˜?
                # - scaler.mean_, scaler.scale_ ë“± ë‚´ë¶€ ì†ì„±ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ
                # - StandardScaler, MinMaxScaler, RobustScaler ë“± ëª¨ë“  ìŠ¤ì¼€ì¼ëŸ¬ ì§€ì›
                # - ë‹¤ë¥¸ íŠ¹ì„±ë“¤ê³¼ì˜ ìƒê´€ê´€ê³„ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ì—­ë³€í™˜
            
            # ================================================================
            # 6-3. ë‹¤ìŒ ë‚ ì§œ ê³„ì‚°
            # ================================================================
            # 15ë¶„ ë‹¨ìœ„ë¡œ ì‹œê°„ ì¦ê°€
            # step=0ì¼ ë•Œ â†’ 15ë¶„ í›„
            # step=1ì¼ ë•Œ â†’ 30ë¶„ í›„
            # step=95ì¼ ë•Œ â†’ 24ì‹œê°„(1ì¼) í›„
            next_date = last_date + timedelta(minutes=15 * (step + 1))
            
            # ================================================================
            # 6-4. í‰ì¼/íœ´ì¼ ê¸°ë°˜ ì•ˆì •í™”
            # ================================================================
            # ì˜ˆì¸¡ê°’ì„ ë°ì´í„° íŒ¨í„´ì— ë§ê²Œ ë³´ì •
            pred_original, stabilized, reason, weekday_name, day_type, icon = adaptive_stabilization(
                pred_original, next_date, patterns
            )
            
            # ì•ˆì •í™”ê°€ ì ìš©ë˜ì—ˆìœ¼ë©´ ë¡œê·¸ì— ê¸°ë¡ (ìµœëŒ€ max_logê°œê¹Œì§€)
            if stabilized and len(stabilization_log) < max_log:
                stabilization_log.append({
                    "step": step,
                    "date": next_date.strftime("%m-%d %H:%M"),
                    "weekday": weekday_name,
                    "type": day_type,
                    "icon": icon,
                    "value": pred_original,
                    "reason": reason
                })
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            future_predictions.append(pred_original)
            future_dates.append(next_date)
            
            # ================================================================
            # 6-5. ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (FIFO ë°©ì‹)
            # ================================================================
            # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                # ë§ˆì§€ë§‰ í–‰ì„ ë³µì‚¬í•˜ì—¬ ìƒˆë¡œìš´ í–‰ ìƒì„±
                next_row = data_for_prediction.iloc[-1].copy().values
                
                # íƒ€ê²Ÿ ìœ„ì¹˜ì— ì˜ˆì¸¡ê°’ ì‚½ì…
                next_row[target_idx] = pred_original
                
                # ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ë™ì  ì—…ë°ì´íŠ¸
                # week_code, is_weekend, is_workday ë“±ì„ ìƒˆë¡œìš´ ë‚ ì§œì— ë§ê²Œ ì—…ë°ì´íŠ¸
                next_row = update_time_features(next_row, next_date, study_columns_list)
                
                # ìƒˆë¡œìš´ í–‰ì„ ì •ê·œí™”
                next_row_scaled = scaler.transform(next_row.reshape(1, -1))[0].astype(np.float32)
                
                # NaN/Inf ì²´í¬ (ì•ˆì „ì„±)
                # ì •ê·œí™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ìµœê·¼ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
                if np.any(np.isnan(next_row_scaled)) or np.any(np.isinf(next_row_scaled)):
                    next_row_scaled = np.mean(current_sequence[-10:], axis=0)
            
            # FIFO(First In First Out) ë°©ì‹ìœ¼ë¡œ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
            # ì²« ë²ˆì§¸ í–‰ ì œê±°, ë§ˆì§€ë§‰ì— ìƒˆ í–‰ ì¶”ê°€
            # Before: [t-672, t-671, ..., t-1, t]
            # After:  [t-671, t-670, ..., t, t+1]
            current_sequence = np.vstack([current_sequence[1:], next_row_scaled.reshape(1, -1)])
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (96ìŠ¤í…ë§ˆë‹¤ = 1ì¼ë§ˆë‹¤)
            if (step + 1) % 96 == 0:
                print(f"   â³ {step + 1}/{future_steps} ì™„ë£Œ ({(step+1)//96}ì¼)")
        
        # ====================================================================
        # 7ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥ ë° ê²€ì¦
        # ====================================================================
        
        # ì•ˆì •í™” ë¡œê·¸ ì¶œë ¥
        if stabilization_log:
            print(f"\n   âš ï¸  ì•ˆì •í™” ì ìš© ì‚¬ë¡€ (ì´ {len(stabilization_log)}ê±´):")
            for log in stabilization_log[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"      {log['icon']} {log['date']} ({log['weekday']}, {log['type']}): "
                      f"{log['value']:.2f} kWh - {log['reason']}")
            if len(stabilization_log) > 5:
                print(f"      ... ì™¸ {len(stabilization_log) - 5}ê±´")
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜ (í†µê³„ ê³„ì‚° ìš©ì´)
        future_predictions = np.array(future_predictions)
        
        # ì˜ˆì¸¡ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"   - ìµœì†Œ: {np.min(future_predictions):.2f} kWh")
        print(f"   - ìµœëŒ€: {np.max(future_predictions):.2f} kWh")
        print(f"   - í‰ê· : {np.mean(future_predictions):.2f} kWh")
        print(f"   - í‘œì¤€í¸ì°¨: {np.std(future_predictions):.2f} kWh")
        
        # ====================================================================
        # 8ë‹¨ê³„: ì˜ˆì¸¡ í’ˆì§ˆ ê²€ì¦
        # ====================================================================
        # ì˜ˆì¸¡ëœ í‰ì¼/íœ´ì¼ í‰ê· ì„ í•™ìŠµ ë°ì´í„°ì™€ ë¹„êµ
        
        workday_predictions = []   # í‰ì¼ ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
        holiday_predictions = []   # íœ´ì¼ ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
        
        # ì˜ˆì¸¡ê°’ì„ í‰ì¼/íœ´ì¼ë¡œ ë¶„ë¦¬
        for pred_val, pred_date in zip(future_predictions, future_dates):
            if pred_date.weekday() < 5:  # í‰ì¼
                workday_predictions.append(pred_val)
            else:  # íœ´ì¼
                holiday_predictions.append(pred_val)
        
        print(f"\n   ğŸ“… ì˜ˆì¸¡ëœ í‰ì¼/íœ´ì¼ í‰ê·  (vs í•™ìŠµ ë°ì´í„°):")
        
        # í‰ì¼ ë¹„êµ
        if workday_predictions:
            pred_workday_avg = np.mean(workday_predictions)
            actual_workday_avg = patterns["workday"]["mean"]
            diff = pred_workday_avg - actual_workday_avg
            diff_pct = (diff / actual_workday_avg * 100) if actual_workday_avg > 0 else 0
            print(f"      ğŸ¢ í‰ì¼: {pred_workday_avg:6.2f} kWh "
                  f"(í•™ìŠµ: {actual_workday_avg:6.2f}, ì°¨ì´: {diff:+6.2f} / {diff_pct:+5.1f}%)")
        
        # íœ´ì¼ ë¹„êµ
        if holiday_predictions:
            pred_holiday_avg = np.mean(holiday_predictions)
            actual_holiday_avg = patterns["holiday"]["mean"]
            diff = pred_holiday_avg - actual_holiday_avg
            diff_pct = (diff / actual_holiday_avg * 100) if actual_holiday_avg > 0 else 0
            print(f"      ğŸ–ï¸ íœ´ì¼: {pred_holiday_avg:6.2f} kWh "
                  f"(í•™ìŠµ: {actual_holiday_avg:6.2f}, ì°¨ì´: {diff:+6.2f} / {diff_pct:+5.1f}%)")
        
        # ====================================================================
        # 9ë‹¨ê³„: ê²°ê³¼ í¬ë§·íŒ…
        # ====================================================================
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥)
        predictions_list = []
        for pred_val, pred_date in zip(future_predictions, future_dates):
            predictions_list.append({
                "date": convert_to_serializable(pred_date),
                "predicted_value": convert_to_serializable(pred_val)
            })
        
        # ====================================================================
        # 10ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ë°˜í™˜
        # ====================================================================
        return {
            "metadata": {
                "model_name": config.get('modelName', 'unknown'),
                "target_column": targetColumn,
                "prediction_steps": future_steps,
                "last_known_date": convert_to_serializable(last_date),
                "method": "í‰ì¼/íœ´ì¼ ê¸°ë°˜ ì ì‘í˜• ì•ˆì •í™”",
                "historical_mean": historical_mean,
                "historical_std": historical_std,
                "learned_patterns": {
                    "workday": patterns["workday"],
                    "holiday": patterns["holiday"]
                }
            },
            "predictions": predictions_list,
            "statistics": {
                "min_predicted": convert_to_serializable(np.min(future_predictions)),
                "max_predicted": convert_to_serializable(np.max(future_predictions)),
                "mean_predicted": convert_to_serializable(np.mean(future_predictions)),
                "std_predicted": convert_to_serializable(np.std(future_predictions))
            }
        }
        
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
        print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def save_predictions_to_db(prediction_result, target_table="usage_generation_forecast"):
    if prediction_result is None:
        return 0, 0
    
    try:
        engine = get_db_engine()
        predictions = prediction_result.get('predictions', [])
        
        if not predictions:
            return 0, 0
        
        print(f"\nğŸ’¾ DB ì €ì¥ ì‹œì‘...")
        
        success_count = 0
        
        with engine.connect() as conn:
            trans = conn.begin()
            
            try:
                for pred in predictions:
                    delete_query = text(f"DELETE FROM carbontwin.{target_table} WHERE time_point = :time_point")
                    conn.execute(delete_query, {"time_point": pred['date']})
                    
                    insert_query = text(f"""
                    INSERT INTO carbontwin.{target_table} (time_point, forecast_usage_kwh, reg_dt)
                    VALUES (:time_point, :forecast_value, CURRENT_TIMESTAMP)
                    """)
                    
                    conn.execute(insert_query, {
                        "time_point": pred['date'],
                        "forecast_value": pred['predicted_value']
                    })
                    
                    success_count += 1
                
                trans.commit()
                print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {success_count}ê±´")
                
            except Exception as e:
                trans.rollback()
                print(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {str(e)}")
                return success_count, len(predictions) - success_count
        
        return success_count, 0
        
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return 0, len(predictions) if predictions else 0

def main(model_name, tablename, future_steps=672, save_to_db_flag=True, validation_days=7):
    print("=" * 80)
    print("âš¡ ì „ë ¥ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ (ê°œì„ ëœ ì—­ì •ê·œí™” ë°©ì‹)")
    print("=" * 80)
    
    model, scaler, config = load_trained_model(model_name)
    if model is None:
        return None
    
    print(f"\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    new_data = load_new_data(tablename, config['dateColumn'], config['studyColumns'])
    if new_data is None or new_data.empty:
        return None
    
    validation_result = validate_with_actual_data(model, scaler, config, new_data, validation_days)
    
    if validation_result:
        val_accuracy = validation_result['statistics']['accuracy']
        print(f"\nâœ… ê²€ì¦ ì •í™•ë„: {val_accuracy:.2f}%")
        
        future_result = predict_future_stable(
            model, scaler, config, new_data, future_steps,
            historical_mean=validation_result.get('historical_mean'),
            historical_std=validation_result.get('historical_std')
        )
        
        if future_result and save_to_db_flag:
            success, fail = save_predictions_to_db(future_result)
            if success > 0:
                print(f"\nâœ… {success}ê±´ ì €ì¥")
    
    print(f"\n{'='*80}")
    print("ğŸ‰ ì™„ë£Œ!")
    print("="*80)
    
    return {"validation": validation_result, "future_prediction": future_result}

if __name__ == "__main__":
    try:
        model_name = "usage-kwh-model-2"
        tablename = "lstm_input_15m_new"
        
        print("\n" + "=" * 80)
        print("âš¡ ê°œì„ ëœ ì—­ì •ê·œí™” ë°©ì‹ ì ìš©")
        print("=" * 80)
        
        result = main(
            model_name=model_name,
            tablename=tablename,
            future_steps=672,
            save_to_db_flag=True,
            validation_days=7
        )
        
        if result and result.get('validation'):
            val_stats = result['validation']['statistics']
            print(f"\n{'='*80}")
            print(f"ğŸ“Š ìµœì¢… ìš”ì•½")
            print(f"{'='*80}")
            print(f"   ì •í™•ë„: {val_stats['accuracy']:.2f}%")
            print(f"   MAPE:   {val_stats['mape']:.2f}%")
            print(f"{'='*80}")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()