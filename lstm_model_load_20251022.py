# -*- coding: utf-8 -*-
"""
Title   : EPS ì„ê³„ê°’ í•„í„°ë§ì´ ì ìš©ëœ LSTM ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸
Author  : ì£¼ì„±ì¤‘ / (ì£¼)ë§µì¸ì–´ìŠ¤
Description: 
    - í•™ìŠµëœ LSTM ëª¨ë¸ë¡œ ì‹ ê·œ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰
    - EPS ì„ê³„ê°’ ê¸°ë°˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ í•„í„°ë§ ì¶”ê°€
    - ë¯¸ë˜ê°’ ì˜ˆì¸¡ ê¸°ëŠ¥ í¬í•¨
    - PostgreSQL DB ì €ì¥ ê¸°ëŠ¥
Version : 2.4
Date    : 2025-10-22
"""

import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
import json
import joblib
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta

# -----------------------------------------------------------------------------
# í™˜ê²½ ì„¤ì • ë¸”ë¡
# -----------------------------------------------------------------------------
ENV = os.getenv('FLASK_ENV', 'local')
if ENV == 'local':
    # ê°œë°œ(ë¡œì»¬) í™˜ê²½ì¼ ë•Œì˜ ë£¨íŠ¸ ê²½ë¡œ
    root = "D:/work/lstm"
else:
    # ë°°í¬(ì»¨í…Œì´ë„ˆ ë“±) í™˜ê²½ì¼ ë•Œì˜ ë£¨íŠ¸ ê²½ë¡œ
    root = "/app/webfiles/lstm"

# ëª¨ë¸ê³¼ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥/ë¶ˆëŸ¬ì˜¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
model_path = os.path.abspath(root + "/saved_models")
prediction_path = os.path.abspath(root + "/predictions")
os.makedirs(prediction_path, exist_ok=True)  # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±

# -----------------------------------------------------------------------------
# ğŸ”¥ EPS ì„ê³„ê°’ ì„¤ì • (ì „ì—­ ë³€ìˆ˜)
# -----------------------------------------------------------------------------
# ì´ ê°’ì€ í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©í•œ ì„ê³„ê°’ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶”ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.
# EPS: Very small energy outputsë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•œ ì„ê³„ê°’ (kWh ë‹¨ìœ„ ì˜ˆì‹œ)
PREDICTION_EPS_THRESHOLD = 0  # 0.1 kWh ì´í•˜ëŠ” ì‹ ë¢°ë„ ë‚®ìŒìœ¼ë¡œ ê°„ì£¼

# -----------------------------------------------------------------------------
# DB ì—°ê²° í•¨ìˆ˜
# -----------------------------------------------------------------------------
def get_db_engine():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì—”ì§„ ìƒì„±

    ë°˜í™˜:
        sqlalchemy Engine ê°ì²´
    ì£¼ì˜:
        - connection_stringì€ í™˜ê²½ë³„ ë¹„ë°€ë²ˆí˜¸/í˜¸ìŠ¤íŠ¸ì— ë”°ë¼ ìˆ˜ì • í•„ìš”
        - ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë¹„ë°€ë²ˆí˜¸ë¥¼ ì½”ë“œì— ì§ì ‘ ë‘ì§€ ë§ê³  í™˜ê²½ë³€ìˆ˜/ì‹œí¬ë¦¿ ë§¤ë‹ˆì € ì‚¬ìš© ê¶Œì¥
    """
    connection_string = "postgresql://postgres:mapinus@10.10.10.201:5432/postgres"
    return create_engine(connection_string)

def convert_to_serializable(obj):
    """NumPy ë° Pandasì˜ íŠ¹ìˆ˜ íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜

    ì‚¬ìš©ì²˜:
        - ì˜ˆì¸¡ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ê±°ë‚˜ DBì— ì €ì¥í•  ë•Œ ì§ë ¬í™” ë¬¸ì œ ë°©ì§€
    ì§€ì› íƒ€ì…:
        - np.ndarray -> list
        - np.integer / np.floating -> int / float
        - pandas Timestamp / datetime -> ISO 8601 ë¬¸ìì—´
    """
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, pd.Timestamp):
        return obj.isoformat()
    elif isinstance(obj, datetime):
        return obj.isoformat()
    return obj

# -----------------------------------------------------------------------------
# ì‹ ê·œ ë°ì´í„° ë¡œë“œ
# -----------------------------------------------------------------------------
def load_new_data(tablename, dateColumn, studyColumns, start_date=None, end_date=None, days_limit=7):
    """PostgreSQL DBì—ì„œ ì˜ˆì¸¡í•  ì‹ ê·œ ë°ì´í„°ë¥¼ ë¡œë“œ

    íŒŒë¼ë¯¸í„°:
        tablename: DB í…Œì´ë¸” ì´ë¦„ (ì¹´íƒ€ë¡œê·¸ ì—†ì´ í…Œì´ë¸”ëª…ë§Œ)
        dateColumn: ì‹œê°„ ì»¬ëŸ¼ëª… (ì˜ˆ: 'time_point')
        studyColumns: ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ë“¤ì˜ ë¬¸ìì—´ (ì½¤ë§ˆ êµ¬ë¶„)
        start_date, end_date: ê¸°ê°„ í•„í„° (ë¬¸ìì—´ ë˜ëŠ” None)
        days_limit: ì‚¬ìš©ë˜ì§„ ì•Šì§€ë§Œ ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë‚¨ê²¨ë‘  (í˜¸ì¶œë¶€ í˜¸í™˜ì„± ìœ ì§€)

    ë°˜í™˜ê°’:
        pandas DataFrame (ì„±ê³µ) ë˜ëŠ” None (ì‹¤íŒ¨)
    ì˜ˆì™¸/ì£¼ì˜:
        - ì¿¼ë¦¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼ëª…ì€ SQL ì¸ì ì…˜ì— ì·¨ì•½í•  ìˆ˜ ìˆìœ¼ë‹ˆ
          ì™¸ë¶€ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ë„£ëŠ” ê²½ìš° ê²€ì¦ í•„ìš”
        - ë„¤íŠ¸ì›Œí¬/DB ì—°ê²° ì‹¤íŒ¨ ì‹œ None ë¦¬í„´
    """
    try:
        engine = get_db_engine()
        
        if start_date is None and end_date is None:
            # ë‚ ì§œ í•„í„°ê°€ ì—†ì„ ë•Œ: ì „ì²´ ë°ì´í„°(ì •ë ¬ í¬í•¨) ì¡°íšŒ
            query = f"""
            SELECT {studyColumns},{dateColumn}
            FROM carbontwin.{tablename}
            WHERE {dateColumn} IS NOT NULL
            ORDER BY {dateColumn} ASC
            """
        else:
            # start/endê°€ ì§€ì •ëœ ê²½ìš° ì¡°ê±´ ìƒì„±
            where_conditions = [f"{dateColumn} IS NOT NULL"]
            if start_date:
                where_conditions.append(f"{dateColumn} >= '{start_date}'")
            if end_date:
                where_conditions.append(f"{dateColumn} <= '{end_date}'")
            
            query = f"""
            SELECT {studyColumns},{dateColumn}
            FROM carbontwin.{tablename}
            WHERE {' AND '.join(where_conditions)}
            ORDER BY {dateColumn} ASC
            """
        
        # pandasì˜ read_sql_queryë¡œ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜
        data = pd.read_sql_query(query, engine)
        print(f"âœ… ì‹ ê·œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}í–‰")
        
        # ë¡œë“œëœ ë°ì´í„°ì˜ ê¸°ê°„ ì •ë³´ ì¶œë ¥(ë””ë²„ê·¸ ëª©ì )
        if len(data) > 0 and dateColumn in data.columns:
            min_date = pd.to_datetime(data[dateColumn]).min()
            max_date = pd.to_datetime(data[dateColumn]).max()
            print(f"   ğŸ“… ë°ì´í„° ê¸°ê°„: {min_date} ~ {max_date}")
        
        return data
        
    except Exception as e:
        # DB/ì¿¼ë¦¬ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ Noneì„ ë°˜í™˜
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

# -----------------------------------------------------------------------------
# ëª¨ë¸ ë¡œë“œ
# -----------------------------------------------------------------------------
def load_trained_model(model_name):
    """ì €ì¥ëœ LSTM ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ì„¤ì • íŒŒì¼ì„ ë¡œë“œ

    íŒŒì¼ êµ¬ì„±(ê´€ë¡€):
        - ëª¨ë¸: {model_name}.h5
        - ìŠ¤ì¼€ì¼ëŸ¬: {model_name}_scaler.pkl (joblibìœ¼ë¡œ ì €ì¥ëœ sklearn ìŠ¤ì¼€ì¼ëŸ¬)
        - ì„¤ì •: {model_name}_config.json (json í¬ë§·, í•„ìˆ˜ í‚¤: studyColumns, targetColumn, dateColumn, r_seqLen ë“±)

    ë°˜í™˜ê°’:
        (model, scaler, config) ë˜ëŠ” (None, None, None) on error

    ì£¼ì˜:
        - load_modelì—ì„œ compile=Falseë¡œ ë¡œë“œí•œ ë’¤ compile í˜¸ì¶œí•¨(í˜¸í™˜ì„± ë³´ì¥)
        - ìŠ¤ì¼€ì¼ëŸ¬/ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ None ë¦¬í„´
    """
    try:
        model_file = os.path.join(model_path, f"{model_name}.h5")
        scaler_file = os.path.join(model_path, f"{model_name}_scaler.pkl")
        config_file = os.path.join(model_path, f"{model_name}_config.json")
        
        if not all(os.path.exists(f) for f in [model_file, scaler_file, config_file]):
            print(f"âŒ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None
        
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        
        # Keras ëª¨ë¸ ë¡œë“œ (ì»´íŒŒì¼ ì˜µì…˜ì€ ë‚˜ì¤‘ì— ì„¤ì •)
        model = load_model(model_file, compile=False)
        model.compile(optimizer='adam', loss='mse')  # ì˜ˆì¸¡ìš©ìœ¼ë¡œ ê¸°ë³¸ ì»´íŒŒì¼
        
        # ìŠ¤ì¼€ì¼ëŸ¬ì™€ config ë¡œë“œ
        scaler = joblib.load(scaler_file)
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # studyColumns ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê³µë°± ì œê±°)
        study_cols_list = [col.strip() for col in config['studyColumns'].split(',')]
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   - íƒ€ê²Ÿ ì»¬ëŸ¼: {config['targetColumn']}")
        print(f"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {config['r_seqLen']}")
        print(f"   - EPS ì„ê³„ê°’: {PREDICTION_EPS_THRESHOLD}")
        
        return model, scaler, config
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None, None, None

# -----------------------------------------------------------------------------
# ğŸ”¥ EPS ê¸°ë°˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def analyze_prediction_reliability(predictions, eps_threshold=PREDICTION_EPS_THRESHOLD):
    """
    ì˜ˆì¸¡ê°’ì˜ ì‹ ë¢°ë„ë¥¼ EPS ì„ê³„ê°’ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„

    ì„¤ëª…:
        - predictions ë°°ì—´ì„ eps_thresholdì™€ ë¹„êµí•˜ì—¬ ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡/ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ìœ¼ë¡œ ë¶„ë¥˜
        - ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ë“¤ì— ëŒ€í•œ ê¸°ë³¸ í†µê³„(min/max/mean/median/std) ê³„ì‚°
        - ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ë“¤ì— ëŒ€í•œ ê¸°ë³¸ í†µê³„(min/max/mean/median) ê³„ì‚°

    ë°˜í™˜ê°’:
        dict í˜•íƒœì˜ ë¶„ì„ ê²°ê³¼:
            {
                "eps_threshold": eps_threshold,
                "total_predictions": total_count,
                "reliable_predictions": reliable_count,
                "unreliable_predictions": unreliable_count,
                "reliability_ratio": ratio,
                "reliable_indices": [...],
                "unreliable_indices": [...],
                "reliable_statistics": {...} or None,
                "unreliable_statistics": {...} or None
            }

    ì£¼ì˜:
        - total_countê°€ 0ì¼ ê²½ìš° ratioëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
        - í†µê³„ê°’ì€ floatë¡œ ë³€í™˜í•˜ì—¬ JSON ì‹œë¦¬ì–¼ë¼ì´ì¦ˆê°€ ê°€ëŠ¥í•˜ë„ë¡ í•¨
    """
    predictions = np.array(predictions)
    
    # EPS ì„ê³„ê°’ ê¸°ë°˜ ë¶„ë¥˜ (ì—´ ê¸°ì¤€)
    reliable_mask = predictions > eps_threshold
    unreliable_mask = ~reliable_mask
    
    reliable_count = np.sum(reliable_mask)
    unreliable_count = np.sum(unreliable_mask)
    total_count = len(predictions)
    
    analysis = {
        "eps_threshold": eps_threshold,
        "total_predictions": total_count,
        "reliable_predictions": reliable_count,
        "unreliable_predictions": unreliable_count,
        "reliability_ratio": reliable_count / total_count if total_count > 0 else 0,
        "reliable_indices": np.where(reliable_mask)[0].tolist(),
        "unreliable_indices": np.where(unreliable_mask)[0].tolist()
    }
    
    # ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’ í†µê³„
    if reliable_count > 0:
        reliable_values = predictions[reliable_mask]
        analysis["reliable_statistics"] = {
            "min": float(np.min(reliable_values)),
            "max": float(np.max(reliable_values)),
            "mean": float(np.mean(reliable_values)),
            "median": float(np.median(reliable_values)),
            "std": float(np.std(reliable_values))
        }
    else:
        analysis["reliable_statistics"] = None
    
    # ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì˜ˆì¸¡ê°’ í†µê³„
    if unreliable_count > 0:
        unreliable_values = predictions[unreliable_mask]
        analysis["unreliable_statistics"] = {
            "min": float(np.min(unreliable_values)),
            "max": float(np.max(unreliable_values)),
            "mean": float(np.mean(unreliable_values)),
            "median": float(np.median(unreliable_values))
        }
    else:
        analysis["unreliable_statistics"] = None
    
    return analysis

# -----------------------------------------------------------------------------
# ğŸ”¥ EPS í•„í„°ë§ì„ ì ìš©í•œ ì˜ˆì¸¡ê°’ ì¶œë ¥ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def print_predictions_with_eps_filter(predictions, dates, eps_threshold=PREDICTION_EPS_THRESHOLD):
    """
    EPS ì„ê³„ê°’ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§ëœ ì˜ˆì¸¡ê°’ì„ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

    ë™ì‘:
        - analyze_prediction_reliabilityë¥¼ í˜¸ì¶œí•´ í†µê³„ ë° ì¸ë±ìŠ¤ë¥¼ ì–»ìŒ
        - ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’(ìµœëŒ€ 20ê°œ)ê³¼ ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ê°’(ìµœëŒ€ 10ê°œ)ì„ í‘œ í˜•íƒœë¡œ ì¶œë ¥
        - ê° ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ê°„ë‹¨í•œ 'ì‹ ë¢°ë„' í…ìŠ¤íŠ¸(ë†’ìŒ/ë³´í†µ/ë‚®ìŒ)ë¥¼ í‘œì‹œ

    ì¶œë ¥ì€ ë””ë²„ê·¸/ëª¨ë‹ˆí„°ë§ ìš©ë„ë¡œ ì‚¬ìš©ë˜ë©°, ì‹¤ì œ ì €ì¥/ì‘ë‹µì€ ë³„ë„ ë¡œì§ì—ì„œ ì²˜ë¦¬
    """
    predictions = np.array(predictions)
    
    # ì‹ ë¢°ë„ ë¶„ì„
    reliability = analyze_prediction_reliability(predictions, eps_threshold)
    
    print(f"\nğŸ“Š EPS ì„ê³„ê°’ ê¸°ë°˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„")
    print(f"{'='*90}")
    print(f"   ğŸ¯ EPS ì„ê³„ê°’: {eps_threshold}")
    print(f"   ğŸ“ˆ ì „ì²´ ì˜ˆì¸¡: {reliability['total_predictions']}ê°œ")
    print(f"   âœ… ì‹ ë¢° ê°€ëŠ¥ ({eps_threshold} ì´ˆê³¼): {reliability['reliable_predictions']}ê°œ "
          f"({reliability['reliability_ratio']*100:.1f}%)")
    print(f"   âš ï¸  ì‹ ë¢° ë¶ˆê°€ ({eps_threshold} ì´í•˜): {reliability['unreliable_predictions']}ê°œ "
          f"({(1-reliability['reliability_ratio'])*100:.1f}%)")
    
    if reliability["reliable_statistics"]:
        stats = reliability["reliable_statistics"]
        print(f"\n   âœ… ì‹ ë¢° ê°€ëŠ¥ ì˜ˆì¸¡ê°’ í†µê³„:")
        print(f"      - ë²”ìœ„: {stats['min']:.4f} ~ {stats['max']:.4f}")
        print(f"      - í‰ê· : {stats['mean']:.4f}")
        print(f"      - ì¤‘ì•™ê°’: {stats['median']:.4f}")
        print(f"      - í‘œì¤€í¸ì°¨: {stats['std']:.4f}")
    
    if reliability["unreliable_statistics"]:
        stats = reliability["unreliable_statistics"]
        print(f"\n   âš ï¸  ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ê°’ í†µê³„:")
        print(f"      - ë²”ìœ„: {stats['min']:.4f} ~ {stats['max']:.4f}")
        print(f"      - í‰ê· : {stats['mean']:.4f}")
    
    print(f"{'='*90}")
    
    # ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’ë§Œ ì¶œë ¥ (ìµœëŒ€ 20ê°œ)
    reliable_indices = reliability['reliable_indices']
    
    if len(reliable_indices) > 0:
        print(f"\nâœ… ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’ (EPS > {eps_threshold}) - ìµœëŒ€ 20ê°œ")
        print(f"{'='*90}")
        print(f"{'ì¸ë±ìŠ¤':>6} {'ë‚ ì§œ/ì‹œê°„':<25} {'ì˜ˆì¸¡ê°’':>12} {'ì‹ ë¢°ë„':>10}")
        print(f"{'-'*90}")
        
        display_count = min(20, len(reliable_indices))
        for i in range(display_count):
            idx = reliable_indices[i]
            date_str = dates[idx].strftime('%Y-%m-%d %H:%M:%S') if hasattr(dates[idx], 'strftime') else str(dates[idx])
            pred_val = predictions[idx]
            # ê°„ë‹¨í•œ ë“±ê¸‰í™”: EPS * 10ì„ ì´ˆê³¼í•˜ë©´ 'ë†’ìŒ', ì•„ë‹ˆë©´ 'ë³´í†µ'
            confidence = "ë†’ìŒ" if pred_val > eps_threshold * 10 else "ë³´í†µ"
            
            print(f"{idx:>6} {date_str:<25} {pred_val:>12.4f} {confidence:>10}")
        
        if len(reliable_indices) > 20:
            print(f"... ({len(reliable_indices) - 20}ê°œ ë” ìˆìŒ)")
        
        print(f"{'='*90}")
    else:
        # ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’ì´ ì•„ì˜ˆ ì—†ì„ ë•Œì˜ ì•ˆë‚´ë¬¸
        print(f"\nâš ï¸  ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   ğŸ’¡ ëª¨ë¸ ì¬í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    # ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ê°’ë„ ì¼ë¶€ ì¶œë ¥ (ì²˜ìŒ 10ê°œë§Œ)
    unreliable_indices = reliability['unreliable_indices']
    
    if len(unreliable_indices) > 0:
        print(f"\nâš ï¸  ì‹ ë¢° ë¶ˆê°€ ì˜ˆì¸¡ê°’ (EPS â‰¤ {eps_threshold}) - ì²˜ìŒ 10ê°œ")
        print(f"{'='*90}")
        print(f"{'ì¸ë±ìŠ¤':>6} {'ë‚ ì§œ/ì‹œê°„':<25} {'ì˜ˆì¸¡ê°’':>12} {'ìƒíƒœ':>10}")
        print(f"{'-'*90}")
        
        display_count = min(10, len(unreliable_indices))
        for i in range(display_count):
            idx = unreliable_indices[i]
            date_str = dates[idx].strftime('%Y-%m-%d %H:%M:%S') if hasattr(dates[idx], 'strftime') else str(dates[idx])
            pred_val = predictions[idx]
            
            print(f"{idx:>6} {date_str:<25} {pred_val:>12.4f} {'âš ï¸ ë‚®ìŒ':>10}")
        
        if len(unreliable_indices) > 10:
            print(f"... ({len(unreliable_indices) - 10}ê°œ ë” ìˆìŒ)")
        
        print(f"{'='*90}")

# -----------------------------------------------------------------------------
# ğŸ”¥ EPS í•„í„°ë§ì´ ì ìš©ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def predict_future_with_eps(model, scaler, config, new_data, future_steps=None, 
                            eps_threshold=PREDICTION_EPS_THRESHOLD, 
                            apply_filter=True):
    """
    EPS ì„ê³„ê°’ í•„í„°ë§ì´ ì ìš©ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡

    ì£¼ìš” ë¡œì§ ìš”ì•½:
        1) ì…ë ¥ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ seq_len êµ¬ê°„ì„ ê°€ì ¸ì™€ ì‹œí€€ìŠ¤ë¥¼ êµ¬ì„±
        2) ë£¨í”„ë¥¼ ëŒë©° í•œ ìŠ¤í…ì”© ì˜ˆì¸¡ (auto-regressive ë°©ì‹)
        3) ì˜ˆì¸¡ ìŠ¤í…ë§ˆë‹¤ ìŠ¤ì¼€ì¼ë§ ì—­ë³€í™˜ì„ í†µí•´ ì›ë‹¨ìœ„ ì˜ˆì¸¡ê°’ì„ ì–»ìŒ
        4) EPS ì„ê³„ê°’ê³¼ ì‹œê°„ëŒ€(ì£¼ê°„/ì•¼ê°„)ì— ë”°ë¼ í•„í„°ë§ ì ìš©
           - pred_original <= eps_threshold -> 0ìœ¼ë¡œ ì„¤ì • (ë…¸ì´ì¦ˆ ì œê±°)
           - ì•¼ê°„(6ì‹œ ë¯¸ë§Œ ë˜ëŠ” 18ì‹œ ì´í›„)ì—ëŠ” ì›ë³¸ì˜ 10%ë§Œ ì ìš© (ì•¼ê°„ ë³´ìˆ˜ì  ì ìš©)
        5) í•„í„°ë§ëœ ê°’ì„ ì‹œí€€ìŠ¤ì— ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ì— ì‚¬ìš©
        6) ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹ ë¢°ë„(0~1)ë¥¼ êµ¬ì„±í•˜ì—¬ ë°˜í™˜

    íŒŒë¼ë¯¸í„°:
        model: Keras í•™ìŠµëœ ëª¨ë¸
        scaler: í•™ìŠµ ë•Œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬ (mean_, scale_ ì†ì„± í•„ìš”)
        config: ëª¨ë¸ ì„¤ì •(dict) - ë°˜ë“œì‹œ 'dateColumn','studyColumns','targetColumn','r_seqLen' í¬í•¨
        new_data: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìµœì‹  ë°ì´í„°(DataFrame)
        future_steps: ì˜ˆì¸¡í•  ìŠ¤í… ìˆ˜ (ê¸°ë³¸ ê°’ì´ Noneì´ë©´ 672ë¡œ ì„¤ì •)
        eps_threshold: EPS ì„ê³„ê°’ (float)
        apply_filter: Trueì´ë©´ í•„í„°ë§ ì ìš©(ì‘ì—… ê¸°ë³¸ê°’)

    ë°˜í™˜ê°’:
        dict í˜•íƒœì˜ ì˜ˆì¸¡ ê²°ê³¼ (ì˜ˆ: predictions ë¦¬ìŠ¤íŠ¸, í†µê³„, ì‹ ë¢°ë„ ë¶„ì„ ë“±)
    """
    try:
        dateColumn = config['dateColumn']
        studyColumns = config['studyColumns']
        targetColumn = config['targetColumn']
        seq_len = int(config['r_seqLen'])
        pred_days = int(config['r_predDays'])
        
        # ê¸°ë³¸ê°’: 7ì¼ì¹˜ (15ë¶„ ê°„ê²© ê°€ì • ì‹œ 7*96 = 672)
        if future_steps is None:
            future_steps = 672  # 7ì¼ = 7 * 96 (15ë¶„ ê°„ê²©)
        
        study_columns_list = [col.strip() for col in studyColumns.split(',')]
        target_idx = study_columns_list.index(targetColumn)
        
        # ë§ˆì§€ë§‰ ì‹œê°„ ì •ë³´ ì¶”ì¶œ: new_dataì˜ ë§ˆì§€ë§‰ í–‰ì˜ dateColumn ì‚¬ìš©
        if dateColumn in new_data.columns:
            last_date = pd.to_datetime(new_data[dateColumn].iloc[-1])
        else:
            last_date = datetime.now()
        
        print(f"\nğŸ”® EPS í•„í„°ë§ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì‹œì‘...")
        print(f"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {seq_len}ê°œ")
        print(f"   - ì˜ˆì¸¡ ìŠ¤í…: {future_steps}ê°œ")
        print(f"   - EPS ì„ê³„ê°’: {eps_threshold}")
        print(f"   - í•„í„°ë§ ì ìš©: {'ì˜ˆ' if apply_filter else 'ì•„ë‹ˆì˜¤'}")
        
        # ì˜ˆì¸¡ì— ì‚¬ìš©í•  ì…ë ¥ ë¶€ë¶„ë§Œ float íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        data_for_prediction = new_data[study_columns_list].astype(float)
        
        # ì…ë ¥ ë°ì´í„°ê°€ ì‹œí€€ìŠ¤ ê¸¸ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ì—ëŸ¬
        if len(data_for_prediction) < seq_len:
            raise ValueError(f"ë°ì´í„° ë¶€ì¡±: {len(data_for_prediction)}ê°œ (ìµœì†Œ {seq_len}ê°œ í•„ìš”)")
        
        # ì •ê·œí™” (scalerë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë³€í™˜ ì ìš©)
        data_scaled = scaler.transform(data_for_prediction)
        
        # ì‹œê°„ ê°„ê²© ê³„ì‚°: ë§ˆì§€ë§‰ ë‘ í–‰ì˜ ì°¨ì´ë¡œ ì‹œê°„ ê°„ê²©ì„ ì¶”ì • (ì—†ìœ¼ë©´ 15ë¶„ ê°€ì •)
        if dateColumn in new_data.columns and len(new_data) > 1:
            dates = pd.to_datetime(new_data[dateColumn])
            time_delta = (dates.iloc[-1] - dates.iloc[-2])
        else:
            time_delta = pd.Timedelta(minutes=15)
        
        # í˜„ì¬ ì‹œí€€ìŠ¤ë¥¼ ë§ˆì§€ë§‰ seq_len ë°ì´í„°ë¡œ ì´ˆê¸°í™”
        current_sequence = data_scaled[-seq_len:].copy()
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ë“¤
        future_predictions = []
        future_predictions_raw = []  # í•„í„°ë§ ì „ ì›ë³¸ê°’
        future_dates = []
        prediction_confidence = []
        
        # ê¸°ì¤€ê°’(baseline) ê³„ì‚°: ìµœê·¼ 100ê°œ ì¤‘ ì–‘ìˆ˜ê°’ì˜ ì¤‘ì•™ê°’ ì‚¬ìš©(ì—†ìœ¼ë©´ eps ì‚¬ìš©)
        recent_data = data_for_prediction[targetColumn].tail(100)
        recent_positive = recent_data[recent_data > eps_threshold]
        baseline = recent_positive.median() if len(recent_positive) > 0 else eps_threshold
        
        print(f"   ğŸ“Š ì˜ˆì¸¡ ê¸°ì¤€ê°’: {baseline:.4f}")
        
        # ì˜ˆì¸¡ ë£¨í”„: ê° ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡í•˜ê³  ì‹œí€€ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸
        for step in range(future_steps):
            next_date = last_date + time_delta * (step + 1)
            hour = next_date.hour
            
            # ëª¨ë¸ ì…ë ¥ í˜•íƒœ ë§ì¶¤: (1, seq_len, feature_count)
            input_data = current_sequence.reshape(1, seq_len, len(study_columns_list))
            pred_scaled = model.predict(input_data, verbose=0)[0, 0]
            
            # ì—­ì •ê·œí™”: scaler.scale_[target_idx]ì™€ mean_[target_idx] ì´ìš©
            pred_original = pred_scaled * scaler.scale_[target_idx] + scaler.mean_[target_idx]
            
            # ì›ë³¸ ì˜ˆì¸¡ê°’ ì €ì¥ (í•„í„° ì ìš© ì „)
            future_predictions_raw.append(pred_original)
            
            # ğŸ”¥ EPS í•„í„°ë§ ì ìš© ë¡œì§:
            # - eps ì´í•˜ì´ë©´ 0ìœ¼ë¡œ ê°•ì œ
            # - ë‚®ì—ëŠ” ê·¸ëŒ€ë¡œ, ë°¤ì—ëŠ” 10%ë§Œ ì ìš© (ë…¸ì´ì¦ˆ ì–µì œ)
            if apply_filter:
                if pred_original <= eps_threshold:
                    pred_filtered = 0.0
                else:
                    if 6 <= hour < 18:
                        pred_filtered = pred_original
                    else:
                        # ì•¼ê°„ ë³´ìˆ˜ì  ì ìš©: ì›ë³¸ì˜ 10%ë§Œ ì‚¬ìš©
                        pred_filtered = max(0, pred_original * 0.1)
            else:
                # í•„í„°ë§ì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ê²½ìš° ìŒìˆ˜ëŠ” 0ìœ¼ë¡œ ë³´ì •
                pred_filtered = max(0, pred_original)
            
            # ì‹ ë¢°ë„ ê³„ì‚°: baselineê³¼ ë¹„êµí•˜ì—¬ 0~1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§ (ë‹¨ìˆœí™”ëœ ë°©ì‹)
            if pred_filtered > eps_threshold:
                confidence = min(1.0, pred_filtered / (baseline * 2))
            else:
                confidence = 0.0
            
            # ê²°ê³¼ë“¤ì— ì¶”ê°€
            future_predictions.append(pred_filtered)
            future_dates.append(next_date)
            prediction_confidence.append(confidence)
            
            # ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•´ ì‹œí€€ìŠ¤ì— ìƒˆ ìƒ˜í”Œì„ ì¶”ê°€
            # - new_pointëŠ” ë§ˆì§€ë§‰ rowì˜ ë³µì‚¬ë³¸ì„ ì‚¬ìš©í•´ ë‹¤ë¥¸ featureëŠ” ìœ ì§€
            # - target ì»¬ëŸ¼ë§Œ ìƒˆ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ëŒ€ì²´ (ìŠ¤ì¼€ì¼ë§ í›„ ë°˜ì˜)
            new_point = current_sequence[-1].copy()
            new_point_scaled = (pred_filtered - scaler.mean_[target_idx]) / scaler.scale_[target_idx]
            new_point[target_idx] = new_point_scaled
            
            # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: ì²« í–‰ ì œê±°í•˜ê³  ìƒˆ í–‰ ì¶”ê°€
            current_sequence = np.vstack([current_sequence[1:], new_point])
            
            # ì§„í–‰ ë¡œê·¸ (ë””ë²„ê·¸ ëª©ì )
            if (step + 1) % 100 == 0:
                print(f"   â³ ì§„í–‰: {step + 1}/{future_steps} ìŠ¤í… ì™„ë£Œ")
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
        
        # ì‹ ë¢°ë„ ë¶„ì„ (EPS ê¸°ì¤€)
        reliability = analyze_prediction_reliability(future_predictions, eps_threshold)
        
        # ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì „ì²´ ì˜ˆì¸¡: {len(future_predictions)}ê°œ")
        print(f"   - ì‹ ë¢° ê°€ëŠ¥: {reliability['reliable_predictions']}ê°œ "
              f"({reliability['reliability_ratio']*100:.1f}%)")
        print(f"   - ì‹ ë¢° ë¶ˆê°€: {reliability['unreliable_predictions']}ê°œ")
        print(f"   - ì˜ˆì¸¡ê°’ ë²”ìœ„: {min(future_predictions):.4f} ~ {max(future_predictions):.4f}")
        
        # í…Œì´ë¸” í˜•íƒœë¡œ ì£¼ìš” ê²°ê³¼ ì¶œë ¥ (ì½˜ì†”)
        print_predictions_with_eps_filter(future_predictions, future_dates, eps_threshold)
        
        # ë°˜í™˜ìš© ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        future_result = {
            "model_name": config['modelName'],
            "target_column": targetColumn,
            "prediction_type": "future_with_eps_filter",
            "base_date": last_date.isoformat(),
            "sequence_length": seq_len,
            "future_steps": future_steps,
            "eps_threshold": eps_threshold,
            "filter_applied": apply_filter,
            "reliability_analysis": reliability,
            "baseline_value": float(baseline),
            "predictions": []
        }
        
        # ê° ìŠ¤í… ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€
        for i, (date, pred, pred_raw, conf) in enumerate(
            zip(future_dates, future_predictions, future_predictions_raw, prediction_confidence)):
            future_result["predictions"].append({
                "step": i + 1,
                "date": date.isoformat(),
                "predicted_value": convert_to_serializable(pred),
                "predicted_value_raw": convert_to_serializable(pred_raw),
                "confidence": convert_to_serializable(conf),
                "hour": date.hour,
                "is_reliable": pred > eps_threshold,
                "is_daytime": 6 <= date.hour < 18
            })
        
        # ì „ì²´ í†µê³„: numpyë¥¼ ì‚¬ìš©í•´ ê°„ë‹¨íˆ ê³„ì‚°í•˜ê³  ì§ë ¬í™” ì¤€ë¹„
        future_result["statistics"] = {
            "min_predicted": convert_to_serializable(np.min(future_predictions)),
            "max_predicted": convert_to_serializable(np.max(future_predictions)),
            "mean_predicted": convert_to_serializable(np.mean(future_predictions)),
            "median_predicted": convert_to_serializable(np.median(future_predictions)),
            "std_predicted": convert_to_serializable(np.std(future_predictions))
        }
        
        return future_result
        
    except Exception as e:
        # ì˜ˆì¸¡ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥ í›„ None ë°˜í™˜
        print(f"âŒ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# -----------------------------------------------------------------------------
# ğŸ”¥ EPS í•„í„°ë§ ì ìš©í•œ DB ì €ì¥ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def save_predictions_to_db_with_eps(prediction_result, target_table="solar_generation_forecast", 
                                    only_reliable=False):
    """
    ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ PostgreSQL DBì— ì €ì¥ (EPS í•„í„°ë§ ì˜µì…˜)

    íŒŒë¼ë¯¸í„°:
        prediction_result: predict_future_with_epsì˜ ë°˜í™˜ dict
        target_table: ì €ì¥ ëŒ€ìƒ í…Œì´ë¸”ëª… (carbontwin.<target_table> ì‚¬ìš©)
        only_reliable: Trueì´ë©´ is_reliable == Trueì¸ ì˜ˆì¸¡ë§Œ ì €ì¥

    ë™ì‘:
        - ê¸°ì¡´ ë™ì¼ time_point ë ˆì½”ë“œëŠ” DELETEë¡œ ì œê±°(ì¤‘ë³µ ë°©ì§€)
        - INSERTë¡œ ìƒˆ ë ˆì½”ë“œ ì¶”ê°€ (time_point, forecast_solar_kwh, reg_dt)
        - íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë¬¶ì–´ ì¤‘ê°„ ì˜¤ë¥˜ ì‹œ ë¡¤ë°±

    ë°˜í™˜ê°’:
        (success_count, fail_count)
    ì£¼ì˜:
        - ì‹¤ì œ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ(ì¹¼ëŸ¼ëª…)ê°€ ë‹¤ë¥´ë©´ INSERTë¬¸ ìˆ˜ì • í•„ìš”
        - ì‹œê°„ í¬ë§·ì€ ISO8601 ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ë¯€ë¡œ DBì˜ time_point ì¹¼ëŸ¼ íƒ€ì…ì— ë§ê²Œ ë³€í™˜ë  ê²ƒ
    """
    if prediction_result is None:
        print("âŒ ì €ì¥í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0, 0
    
    try:
        engine = get_db_engine()
        predictions = prediction_result.get('predictions', [])
        
        if not predictions:
            print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return 0, 0
        
        # only_reliable ì˜µì…˜ì— ë”°ë¼ í•„í„°ë§
        if only_reliable:
            predictions = [p for p in predictions if p.get('is_reliable', False)]
            print(f"\nğŸ“Š ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ë§Œ ì €ì¥: {len(predictions)}ê±´")
        
        print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ DB ì €ì¥ ì‹œì‘...")
        print(f"   - ëŒ€ìƒ í…Œì´ë¸”: carbontwin.{target_table}")
        print(f"   - ì €ì¥í•  ë°ì´í„°: {len(predictions)}ê±´")
        
        success_count = 0
        fail_count = 0
        
        # DB ì»¤ë„¥ì…˜ê³¼ íŠ¸ëœì­ì…˜ ì²˜ë¦¬
        with engine.connect() as conn:
            trans = conn.begin()
            
            try:
                for pred in predictions:
                    time_point = pred['date']
                    forecast_value = pred['predicted_value']
                    
                    # ì¤‘ë³µ ì œê±°: ë™ì¼ time_pointì¸ ê²½ìš° ì‚­ì œ(ì •ì±…)
                    delete_query = text(f"""
                    DELETE FROM carbontwin.{target_table}
                    WHERE time_point = :time_point
                    """)
                    
                    conn.execute(delete_query, {"time_point": time_point})
                    
                    # ì‚½ì…: ê¸°ë³¸ ì»¬ëŸ¼ëª… ì‚¬ìš© (í•„ìš”ì‹œ ìˆ˜ì •)
                    insert_query = text(f"""
                    INSERT INTO carbontwin.{target_table} 
                        (time_point, forecast_solar_kwh, reg_dt)
                    VALUES 
                        (:time_point, :forecast_value, CURRENT_TIMESTAMP)
                    """)
                    
                    conn.execute(
                        insert_query,
                        {
                            "time_point": time_point,
                            "forecast_value": forecast_value
                        }
                    )
                    
                    success_count += 1
                    
                    # ëŒ€ëŸ‰ ì‚½ì…ì‹œ ì§„í–‰ ë¡œê·¸ ì¶œë ¥(ë””ë²„ê·¸/ëª¨ë‹ˆí„°ë§)
                    if success_count % 100 == 0:
                        print(f"   â³ ì§„í–‰: {success_count}/{len(predictions)} ê±´")
                
                trans.commit()
                
                print(f"âœ… DB ì €ì¥ ì™„ë£Œ!")
                print(f"   - ì„±ê³µ: {success_count}ê±´")
                
            except Exception as e:
                trans.rollback()
                print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ (ë¡¤ë°±ë¨): {str(e)}")
                return success_count, len(predictions) - success_count
        
        return success_count, fail_count
        
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return 0, len(predictions) if predictions else 0

# -----------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def main(model_name=None, tablename=None, save_to_db=True, only_reliable=False, 
         eps_threshold=PREDICTION_EPS_THRESHOLD, apply_filter=True):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

    ë™ì‘ ìš”ì•½:
        1. ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/ì„¤ì • ë¡œë“œ
        2. DBì—ì„œ ì‹ ê·œ ë°ì´í„° ë¡œë“œ
        3. predict_future_with_epsë¡œ ë¯¸ë˜ ì˜ˆì¸¡ ìˆ˜í–‰
        4. save_predictions_to_db_with_epsë¡œ DBì— ì €ì¥ (ì˜µì…˜)
        5. ì˜ˆì™¸/ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì ˆíˆ ë©”ì‹œì§€ ì¶œë ¥

    ë°˜í™˜ê°’:
        predict_future_with_epsê°€ ë°˜í™˜í•œ ê²°ê³¼ dict ë˜ëŠ” None
    """
    print("=" * 70)
    print("ğŸ”® EPS í•„í„°ë§ ì ìš© LSTM ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 70)
    
    # ëª¨ë¸ ë¡œë“œ
    model, scaler, config = load_trained_model(model_name)
    
    if model is None:
        return None
    
    if tablename is None:
        tablename = "lstm_input_15m_new"
    
    print(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    # load_new_dataì˜ days_limit íŒŒë¼ë¯¸í„°ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ í˜¸ì¶œ
    new_data = load_new_data(tablename, config['dateColumn'], config['studyColumns'], days_limit=7)
    
    if new_data is None or new_data.empty:
        print("âŒ ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì˜ˆì¸¡ ìŠ¤í… ê¸°ë³¸: 7ì¼
    future_steps = 672  # 7ì¼
    
    print(f"\nğŸ”® ë¯¸ë˜ê°’ ì˜ˆì¸¡ ìˆ˜í–‰")
    print(f"   - ì˜ˆì¸¡ ìŠ¤í…: {future_steps}ê°œ")
    print(f"   - EPS ì„ê³„ê°’: {eps_threshold}")
    print(f"   - í•„í„°ë§ ì ìš©: {'ì˜ˆ' if apply_filter else 'ì•„ë‹ˆì˜¤'}")
    
    # ì‹¤ì œ ì˜ˆì¸¡ í˜¸ì¶œ
    future_result = predict_future_with_eps(
        model, scaler, config, new_data, future_steps,
        eps_threshold, apply_filter
    )
    
    # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆê³  DB ì €ì¥ ì˜µì…˜ì´ ì¼œì ¸ ìˆìœ¼ë©´ ì €ì¥ ìˆ˜í–‰
    if future_result and save_to_db:
        success, fail = save_predictions_to_db_with_eps(
            future_result, 
            only_reliable=only_reliable
        )
        
        if success > 0:
            print(f"\nâœ… ì´ {success}ê±´ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if only_reliable:
                print(f"   ğŸ’¡ ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ë§Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if fail > 0:
            print(f"âš ï¸  {fail}ê±´ì˜ ì €ì¥ ì‹¤íŒ¨")
    
    print(f"\n{'='*70}")
    print("ğŸ‰ ì˜ˆì¸¡ ì™„ë£Œ!")
    print("="*70)
    
    return future_result

# -----------------------------------------------------------------------------
# í”„ë¡œê·¸ë¨ ì‹œì‘ì 
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    """
    EPS í•„í„°ë§ ì ìš© ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

    ì‚¬ìš©ë²•:
        python lstm_predict_with_eps.py

    ì‹¤í–‰ì‹œ ì œê³µë˜ëŠ” ì˜µì…˜:
        - ì‚¬ìš©ìê°€ ì½˜ì†”ì—ì„œ ëª¨ë“œë¥¼ ì„ íƒí•˜ê³  EPS ê°’ ì…ë ¥ ê°€ëŠ¥
        - ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ëª…ê³¼ í…Œì´ë¸”ëª…ì€ ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ì˜ ê¸°ë³¸ê°’ì„ ì‚¬ìš©
    """
    try:
        model_name = "solar-hybrid-seq-2-test-20251017-test-no-add-test"
        tablename = "lstm_input_15m_new"
        
        print("\n" + "=" * 80)
        print("ğŸ” ì‹¤í–‰ ëª¨ë“œ ì„ íƒ")
        print("=" * 80)
        print("\n1. EPS í•„í„°ë§ ì ìš© ì˜ˆì¸¡ (ê¶Œì¥)")
        # ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ "1" ì‚¬ìš©
        
        # EPS ì„ê³„ê°’ ì„¤ì •: ì…ë ¥ì´ ì—†ìœ¼ë©´ ì „ì—­ê°’ ì‚¬ìš©
        eps_threshold = PREDICTION_EPS_THRESHOLD;
        
        print(f"\nâš™ï¸  ì„¤ì •:")
        print(f"   - EPS ì„ê³„ê°’: {eps_threshold}")
        
        # EPS í•„í„°ë§ ì ìš©, ì „ì²´ ì €ì¥
        print(f"   - í•„í„°ë§: ì ìš©")
        print(f"   - DB ì €ì¥: ì „ì²´")

        main(
                model_name=model_name,
                tablename=tablename,
                save_to_db=True,
                only_reliable=False,
                eps_threshold=eps_threshold,
                apply_filter=True
            )
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


# -----------------------------------------------------------------------------
# ğŸ“š ì‚¬ìš© ì˜ˆì‹œ ë° ê°€ì´ë“œ (ë¬¸ì„œí™” ì£¼ì„)
# -----------------------------------------------------------------------------
"""
ğŸ¯ EPS ì„ê³„ê°’ í•„í„°ë§ì˜ ì¥ì :

1. **ì‹ ë¢°ë„ ë†’ì€ ì˜ˆì¸¡ë§Œ ì„ ë³„**
   - EPS ì´í•˜ì˜ ë¶ˆì•ˆì •í•œ ì˜ˆì¸¡ê°’ ì œê±°
   - ì•¼ê°„(0 ê·¼ì²˜) ì˜ˆì¸¡ì˜ ë…¸ì´ì¦ˆ ê°ì†Œ

2. **í•™ìŠµ ì½”ë“œì™€ ì¼ê´€ì„± ìœ ì§€**
   - í•™ìŠµ ì‹œ MAPE ê³„ì‚°ì— ì‚¬ìš©í•œ ë™ì¼í•œ ì„ê³„ê°’ ì ìš©
   - í‰ê°€ ê¸°ì¤€ê³¼ ì˜ˆì¸¡ ê¸°ì¤€ ì¼ì¹˜

3. **ë°ì´í„° í’ˆì§ˆ í–¥ìƒ**
   - DBì— ì €ì¥ë˜ëŠ” ì˜ˆì¸¡ê°’ì˜ ì‹ ë¢°ë„ í–¥ìƒ
   - í›„ì† ë¶„ì„ ì‹œ ë” ì•ˆì •ì ì¸ ë°ì´í„° ì‚¬ìš©

4. **ìœ ì—°í•œ ì„¤ì •**
   - eps_threshold ê°’ ì¡°ì • ê°€ëŠ¥
   - only_reliable ì˜µì…˜ìœ¼ë¡œ ì €ì¥ ë²”ìœ„ ì„ íƒ
   - apply_filter ì˜µì…˜ìœ¼ë¡œ í•„í„°ë§ on/off

ğŸ“Š ê¶Œì¥ EPS ì„ê³„ê°’:
   - íƒœì–‘ê´‘ ë°œì „ëŸ‰: 0.1 ~ 1.0 kWh
   - ì „ë ¥ ì‚¬ìš©ëŸ‰: 1.0 ~ 5.0 kWh
   - ì˜¨ë„ ì˜ˆì¸¡: 0.5 ~ 1.0Â°C

ğŸ’¡ ì‚¬ìš© íŒ:
   1. ë¨¼ì € eps_threshold=0.1ë¡œ í…ŒìŠ¤íŠ¸
   2. ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼ í™•ì¸
   3. í•„ìš”ì‹œ ì„ê³„ê°’ ì¡°ì •
   4. only_reliable=Trueë¡œ ì‹ ë¢° ê°€ëŠ¥í•œ ì˜ˆì¸¡ë§Œ ì €ì¥

âš ï¸  ì£¼ì˜ì‚¬í•­:
   - ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ëŒ€ë¶€ë¶„ì˜ ì˜ˆì¸¡ì´ ì œì™¸ë¨
   - ì„ê³„ê°’ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë…¸ì´ì¦ˆê°€ ë§ì€ ì˜ˆì¸¡ í¬í•¨
   - ëª¨ë¸ ì¬í•™ìŠµ ì‹œ ë™ì¼í•œ ì„ê³„ê°’ ì‚¬ìš© ê¶Œì¥

ğŸ”§ ì¶”ê°€ ê°œì„  ë°©í–¥:
   1. ì‹œê°„ëŒ€ë³„ ì„ê³„ê°’ ì ìš© (ì£¼ê°„/ì•¼ê°„ ë‹¤ë¥´ê²Œ)
   2. ì‹ ë¢°ë„ ì ìˆ˜ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
   3. ì´ìƒì¹˜ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ê²°í•©
   4. ì•™ìƒë¸” ì˜ˆì¸¡ê³¼ ê²°í•©
"""
