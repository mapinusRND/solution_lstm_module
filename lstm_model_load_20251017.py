# -*- coding: utf-8 -*-
"""
Title   : ê°œì„ ëœ LSTM ëª¨ë¸ ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ (DB ì €ì¥ + GPU ì§€ì›)
Author  : ì£¼ì„±ì¤‘ / (ì£¼)ë§µì¸ì–´ìŠ¤
Description: 
    - í•™ìŠµëœ LSTM ëª¨ë¸ë¡œ ì‹ ê·œ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰
    - ì¤‘ë³µ ì˜ˆì¸¡ê°’ ë¬¸ì œ í•´ê²°
    - ë¯¸ë˜ê°’ ì˜ˆì¸¡ ê¸°ëŠ¥ í¬í•¨
    - PostgreSQL DB ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€ (ì¤‘ë³µ ì‹œ DELETE í›„ INSERT)
    - GPU ê°€ì† ì§€ì›
Version : 2.2
Date    : 2025-10-16
"""

import os
# TensorFlow ì„¤ì •: ìµœì í™” ê²½ê³  ë° ë¡œê·¸ ë ˆë²¨ ì¡°ì •
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # OneDNN ìµœì í™” ë¹„í™œì„±í™”
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   # ì—ëŸ¬ë§Œ ì¶œë ¥ (0=ëª¨ë“ ë¡œê·¸, 1=INFOì œì™¸, 2=WARNINGì œì™¸, 3=ERRORë§Œ)

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
import json
import joblib
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta

# ============================================================================
# GPU ì„¤ì • ë° í™•ì¸
# ============================================================================
def setup_gpu():
    """
    GPU ì„¤ì • ë° ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Returns:
    --------
    bool : GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    """
    print("\n" + "=" * 70)
    print("ğŸ® GPU ì„¤ì • í™•ì¸")
    print("=" * 70)
    
    # TensorFlow ë²„ì „ ì¶œë ¥
    print(f"ğŸ“Œ TensorFlow ë²„ì „: {tf.__version__}")
    
    # GPU ë””ë°”ì´ìŠ¤ ëª©ë¡ í™•ì¸
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        try:
            # ================================================================
            # GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ ì„¤ì • (ê¶Œì¥)
            # ================================================================
            # GPU ë©”ëª¨ë¦¬ë¥¼ í•œ ë²ˆì— ëª¨ë‘ í• ë‹¹í•˜ì§€ ì•Šê³ , í•„ìš”í•œ ë§Œí¼ë§Œ ë™ì ìœ¼ë¡œ í• ë‹¹
            # ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ GPUë¥¼ ê³µìœ í•  ë•Œ ìœ ìš©
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            
            # GPU ê°œìˆ˜ ë° ì´ë¦„ ì¶œë ¥
            print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {len(gpus)}ê°œ")
            for i, gpu in enumerate(gpus):
                print(f"   GPU {i}: {gpu.name}")
                # GPU ë©”ëª¨ë¦¬ ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
                try:
                    gpu_details = tf.config.experimental.get_device_details(gpu)
                    if 'device_name' in gpu_details:
                        print(f"        ëª¨ë¸ëª…: {gpu_details['device_name']}")
                except:
                    pass
            
            # CUDA ë° cuDNN ë²„ì „ í™•ì¸
            build_info = tf.sysconfig.get_build_info()
            print(f"   CUDA ë²„ì „: {build_info.get('cuda_version', 'N/A')}")
            print(f"   cuDNN ë²„ì „: {build_info.get('cudnn_version', 'N/A')}")
            
            # ë…¼ë¦¬ì  GPU ëª©ë¡ (ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì • í›„)
            logical_gpus = tf.config.list_logical_devices('GPU')
            print(f"   ë…¼ë¦¬ì  GPU: {len(logical_gpus)}ê°œ")
            
            print("\nğŸ’¡ GPU ê°€ì†ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
            
        except RuntimeError as e:
            # GPU ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ
            print(f"âŒ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
            print("âš ï¸  CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            return False
    else:
        # GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        print("âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        print("\nğŸ“ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:")
        print("   1. NVIDIA GPU ë“œë¼ì´ë²„ ì„¤ì¹˜")
        print("   2. CUDA Toolkit ì„¤ì¹˜ (11.8 ë˜ëŠ” 12.x)")
        print("   3. cuDNN ì„¤ì¹˜")
        print("   4. TensorFlow GPU ë²„ì „ ì„¤ì¹˜: pip install tensorflow[and-cuda]")
        return False

# GPU ì„¤ì • ì‹¤í–‰
gpu_available = setup_gpu()

# ============================================================================
# í™˜ê²½ ì„¤ì •
# ============================================================================
# ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ ê²½ë¡œ ìë™ ì„¤ì • (ë¡œì»¬ ê°œë°œ í™˜ê²½ vs ì„œë²„ ë°°í¬ í™˜ê²½)
ENV = os.getenv('FLASK_ENV', 'local')
if ENV == 'local':
    root = "D:/work/lstm"  # ë¡œì»¬ ê°œë°œ í™˜ê²½ ê²½ë¡œ
else:
    root = "/app/webfiles/lstm"  # ì„œë²„ ë°°í¬ í™˜ê²½ ê²½ë¡œ

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ë° ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
model_path = os.path.abspath(root + "/saved_models")
prediction_path = os.path.abspath(root + "/predictions")
os.makedirs(prediction_path, exist_ok=True)  # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ============================================================================
# DB ì—°ê²° í•¨ìˆ˜
# ============================================================================
def get_db_engine():
    """
    PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì—”ì§„ ìƒì„±
    
    Returns:
        sqlalchemy.engine.Engine: DB ì—°ê²° ì—”ì§„
    """
    # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ë¡œ ê´€ë¦¬ ê¶Œì¥
    connection_string = "postgresql://postgres:mapinus@10.10.10.201:5432/postgres"
    return create_engine(connection_string)

# ============================================================================
# ì‹ ê·œ ë°ì´í„° ë¡œë“œ
# ============================================================================
def load_new_data(tablename, dateColumn, studyColumns, start_date=None, end_date=None):
    """
    PostgreSQL DBì—ì„œ ì˜ˆì¸¡í•  ì‹ ê·œ ë°ì´í„°ë¥¼ ë¡œë“œ
    
    Parameters:
    -----------
    tablename : str
        ì¡°íšŒí•  í…Œì´ë¸”ëª… (ì˜ˆ: 'lstm_input_15m_new')
    dateColumn : str
        ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ëª… (ì˜ˆ: 'timestamp')
    studyColumns : str
        ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•œ ë¬¸ìì—´ (ì˜ˆ: 'temp,humidity,solar_kwh')
    start_date : str, optional
        ì¡°íšŒ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹), Noneì´ë©´ ì „ì²´ ì¡°íšŒ
    end_date : str, optional
        ì¡°íšŒ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹), Noneì´ë©´ ì „ì²´ ì¡°íšŒ
        
    Returns:
    --------
    pandas.DataFrame : ë¡œë“œëœ ë°ì´í„° (ì‹¤íŒ¨ì‹œ None)
    """
    try:
        engine = get_db_engine()
        
        # ê¸°ë³¸ ì¿¼ë¦¬: ì „ì²´ ë°ì´í„° ì¡°íšŒ
        query = f"""
        SELECT {studyColumns},{dateColumn}
        FROM carbontwin.{tablename}
        WHERE {dateColumn} IS NOT NULL
        ORDER BY {dateColumn} ASC
        """
        
        
        # ë‚ ì§œ ë²”ìœ„ê°€ ì§€ì •ëœ ê²½ìš° WHERE ì¡°ê±´ ì¶”ê°€
        if start_date or end_date:
            where_conditions = [f"{dateColumn} IS NOT NULL"]
            if start_date:
                where_conditions.append(f"{dateColumn} >= '{start_date}'")
            if end_date:
                where_conditions.append(f"{dateColumn} <= '{end_date}'")
            
            query = f"""
            SELECT {studyColumns},{dateColumn}
            FROM carbontwin.{tablename}
            WHERE {' AND '.join(where_conditions)}
            ORDER BY {dateColumn} ASC
            """
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° DataFrameìœ¼ë¡œ ë³€í™˜
        data = pd.read_sql_query(query, engine)
        print(f"âœ… ì‹ ê·œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}í–‰ (í…Œì´ë¸”: {tablename})")
        return data
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

# ============================================================================
# NumPy/Pandas íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
# ============================================================================
def convert_to_serializable(obj):
    """
    NumPy ë° Pandasì˜ íŠ¹ìˆ˜ íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    
    Parameters:
    -----------
    obj : any
        ë³€í™˜í•  ê°ì²´ (np.ndarray, np.int64, np.float64, pd.Timestamp ë“±)
        
    Returns:
    --------
    any : JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì… (list, int, float, str)
    
    Notes:
    ------
    JSON íŒŒì¼ ì €ì¥ ì‹œ "Object of type float32 is not JSON serializable" 
    ê°™ì€ ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜
    """
    if isinstance(obj, np.ndarray):
        return obj.tolist()  # NumPy ë°°ì—´ â†’ Python ë¦¬ìŠ¤íŠ¸
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)  # NumPy ì •ìˆ˜ â†’ Python int
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)  # NumPy ì‹¤ìˆ˜ â†’ Python float
    elif isinstance(obj, pd.Timestamp):
        return obj.isoformat()  # Pandas Timestamp â†’ ISO ë¬¸ìì—´
    elif isinstance(obj, datetime):
        return obj.isoformat()  # datetime â†’ ISO ë¬¸ìì—´
    return obj

# ============================================================================
# ëª¨ë¸ ë¡œë“œ
# ============================================================================
def load_trained_model(model_name):
    """
    ì €ì¥ëœ LSTM ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ì„¤ì • íŒŒì¼ì„ ë¡œë“œ
    GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ìë™ìœ¼ë¡œ GPUì—ì„œ ì‹¤í–‰ë¨
    
    Parameters:
    -----------
    model_name : str
        ë¡œë“œí•  ëª¨ë¸ëª… (ì˜ˆ: 'solar-hybrid-seq-2-test-20251017-test-no')
        
    Returns:
    --------
    tuple : (model, scaler, config)
        - model: Keras LSTM ëª¨ë¸ ê°ì²´
        - scaler: StandardScaler ê°ì²´ (ë°ì´í„° ì •ê·œí™”ìš©)
        - config: dict (ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì„¤ì • ì •ë³´)
        ì‹¤íŒ¨ ì‹œ (None, None, None) ë°˜í™˜
        
    Notes:
    ------
    ëª¨ë¸ íŒŒì¼ êµ¬ì¡°:
    - {model_name}.h5: Keras ëª¨ë¸ ê°€ì¤‘ì¹˜
    - {model_name}_scaler.pkl: StandardScaler ê°ì²´
    - {model_name}_config.json: ëª¨ë¸ ì„¤ì • (ì»¬ëŸ¼ëª…, ì‹œí€€ìŠ¤ ê¸¸ì´ ë“±)
    """
    try:
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        model_file = os.path.join(model_path, f"{model_name}.h5")
        scaler_file = os.path.join(model_path, f"{model_name}_scaler.pkl")
        config_file = os.path.join(model_path, f"{model_name}_config.json")
        
        # í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(model_file):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_file}")
            return None, None, None
        if not os.path.exists(scaler_file):
            print(f"âŒ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scaler_file}")
            return None, None, None
        if not os.path.exists(config_file):
            print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}")
            return None, None, None
        
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        
        # GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUì—ì„œ ëª¨ë¸ ë¡œë“œ
        if gpu_available:
            with tf.device('/GPU:0'):  # ì²« ë²ˆì§¸ GPU ì‚¬ìš©
                model = load_model(model_file, compile=False)
                model.compile(optimizer='adam', loss='mse')
                print(f"   ğŸ® GPUì— ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        else:
            # CPUì—ì„œ ëª¨ë¸ ë¡œë“œ
            model = load_model(model_file, compile=False)
            model.compile(optimizer='adam', loss='mse')
            print(f"   ğŸ’» CPUì— ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì •ê·œí™” íŒŒë¼ë¯¸í„°)
        scaler = joblib.load(scaler_file)
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ (JSON)
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # í•™ìŠµ ì»¬ëŸ¼ ì •ë³´ íŒŒì‹±
        study_cols_list = [col.strip() for col in config['studyColumns'].split(',')]
        
        # ë¡œë“œ ì™„ë£Œ ì •ë³´ ì¶œë ¥
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   - íƒ€ê²Ÿ ì»¬ëŸ¼: {config['targetColumn']}")  # ì˜ˆì¸¡í•  ë³€ìˆ˜
        print(f"   - í•™ìŠµ ì»¬ëŸ¼ ({len(study_cols_list)}ê°œ): {config['studyColumns']}")  # ì…ë ¥ ë³€ìˆ˜ë“¤
        print(f"   - ë‚ ì§œ ì»¬ëŸ¼ : {config['dateColumn']}")  # ì…ë ¥ ë³€ìˆ˜ë“¤
        print(f"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {config['r_seqLen']}")  # LSTM ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´
        print(f"   - ì˜ˆì¸¡ ì¼ìˆ˜: {config['r_predDays']}")  # ëª‡ ìŠ¤í… ì•ì„ ì˜ˆì¸¡í•˜ëŠ”ì§€
        
        return model, scaler, config
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None, None

# ============================================================================
# ğŸ”¥ ê°œì„ ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ (ì¤‘ë³µ ì˜ˆì¸¡ ë¬¸ì œ í•´ê²° + GPU ê°€ì†)
# ============================================================================
def predict_future_improved(model, scaler, config, new_data, future_steps=None):
    """
    ê°œì„ ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ - ì¬ê·€ì  ì˜ˆì¸¡ìœ¼ë¡œ ì‹¤ì œ ë¯¸ë˜ê°’ ìƒì„±
    GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ìë™ìœ¼ë¡œ GPUì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰
    
    ê°œì„ ì‚¬í•­:
    1. ì‹œê°„ ì •ë³´ ì¶”ê°€ (ì‹œê°„, ë¶„) - íƒœì–‘ê´‘ ë°œì „ì€ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ì´ ì¤‘ìš”
    2. ë” ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆ ì¶”ê°€ - ì˜ˆì¸¡ì˜ ë‹¤ì–‘ì„± í™•ë³´
    3. ì˜ˆì¸¡ê°’ ë²”ìœ„ ê²€ì¦ - ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ ì ìš© (ì•¼ê°„=0)
    4. ì•™ìƒë¸” ì˜ˆì¸¡ - ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡í•˜ì—¬ í‰ê·  (ì•ˆì •ì„± í–¥ìƒ)
    5. GPU ê°€ì† ì§€ì› - ì˜ˆì¸¡ ì†ë„ í–¥ìƒ
    
    Parameters:
    -----------
    model : Keras Model
        í•™ìŠµëœ LSTM ëª¨ë¸
    scaler : StandardScaler
        í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬
    config : dict
        ëª¨ë¸ ì„¤ì • ì •ë³´
    new_data : DataFrame
        ê¸°ì¤€ì´ ë˜ëŠ” ìµœê·¼ ë°ì´í„°
    future_steps : int, optional
        ì˜ˆì¸¡í•  ë¯¸ë˜ ìŠ¤í… ìˆ˜ (Noneì´ë©´ ìë™ ê³„ì‚°: max(10, seq_len//2))
        
    Returns:
    --------
    dict : ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼
        - predictions: ê° ìŠ¤í…ë³„ ì˜ˆì¸¡ê°’, ì‹œê°„ ì •ë³´
        - statistics: ì˜ˆì¸¡ê°’ í†µê³„ (ìµœì†Œ, ìµœëŒ€, í‰ê· , í‘œì¤€í¸ì°¨)
    """
    try:
        # ì„¤ì • ì •ë³´ ì¶”ì¶œ
        dateColumn = config['dateColumn']
        studyColumns = config['studyColumns']
        targetColumn = config['targetColumn']
        seq_len = int(config['r_seqLen'])  # LSTM ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´
        pred_days = int(config['r_predDays'])  # ì˜ˆì¸¡ ê°„ê²©
        
        # ë¯¸ë˜ ìŠ¤í… ìˆ˜ ìë™ ê³„ì‚° (ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
        if future_steps is None:
            future_steps = max(10, seq_len // 2)  # ìµœì†Œ 10, ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ì˜ ì ˆë°˜
        
        # ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° íƒ€ê²Ÿ ì¸ë±ìŠ¤ ì°¾ê¸°
        study_columns_list = [col.strip() for col in studyColumns.split(',')]
        target_idx = study_columns_list.index(targetColumn)  # ì˜ˆì¸¡í•  ë³€ìˆ˜ì˜ ì¸ë±ìŠ¤
        
        # ë§ˆì§€ë§‰ ë‚ ì§œ ì¶”ì¶œ (ê¸°ì¤€ ì‹œì )
        if dateColumn in new_data.columns:
            last_date = pd.to_datetime(new_data[dateColumn].iloc[-1])
        else:
            last_date = datetime.now()
        
        # ë°ì´í„° ì¤€ë¹„ ë° ì •ê·œí™”
        data_for_prediction = new_data[study_columns_list].astype(float)
        data_scaled = scaler.transform(data_for_prediction)  # StandardScalerë¡œ ì •ê·œí™”
        
        print(f"\nğŸ”® ê°œì„ ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì‹œì‘...")
        print(f"   - ê¸°ì¤€ ì‹œí€€ìŠ¤ ê¸¸ì´: {seq_len}ê°œ")
        print(f"   - ì˜ˆì¸¡ ì‹œì‘ì : {last_date}")
        print(f"   - ì˜ˆì¸¡í•  ë¯¸ë˜ ìŠ¤í…: {future_steps}ê°œ")
        if gpu_available:
            print(f"   - ì‹¤í–‰ í™˜ê²½: ğŸ® GPU ê°€ì†")
        else:
            print(f"   - ì‹¤í–‰ í™˜ê²½: ğŸ’» CPU")
        
        # ì‹œê°„ ê°„ê²© ê³„ì‚° (ë°ì´í„°ì˜ í‰ê·  ì‹œê°„ ê°„ê²©)
        if dateColumn in new_data.columns and len(new_data) > 1:
            dates = pd.to_datetime(new_data[dateColumn])
            time_delta = (dates.iloc[-1] - dates.iloc[-2])  # ë§ˆì§€ë§‰ ë‘ ë°ì´í„°ì˜ ì‹œê°„ ì°¨ì´
        else:
            time_delta = pd.Timedelta(minutes=1)  # ê¸°ë³¸ê°’: 1ë¶„
        
        # ì´ˆê¸° ì‹œí€€ìŠ¤ ì„¤ì • (ë§ˆì§€ë§‰ seq_len ê°œ ë°ì´í„°)
        current_sequence = data_scaled[-seq_len:].copy()
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        future_predictions = []  # ì˜ˆì¸¡ê°’
        future_dates = []  # ì˜ˆì¸¡ ë‚ ì§œ
        prediction_confidence = []  # ì‹ ë¢°ë„ (ë‚´ë¶€ ì‚¬ìš©ìš©)
        
        # ğŸ”¥ ì•™ìƒë¸” ì˜ˆì¸¡ ì„¤ì • (ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡í•˜ì—¬ í‰ê· )
        n_ensemble = 5  # 5ë²ˆ ì˜ˆì¸¡í•˜ì—¬ í‰ê·  ì‚¬ìš©
        
        # ====================================================================
        # ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ì‹œê°„ ê¸°ë¡
        # ====================================================================
        import time
        start_time = time.time()
        prediction_times = []  # ê° ìŠ¤í…ë³„ ì˜ˆì¸¡ ì‹œê°„ ê¸°ë¡
        
        # ì¬ê·€ì  ì˜ˆì¸¡ ë£¨í”„ (ê° ë¯¸ë˜ ìŠ¤í…ë§ˆë‹¤ ë°˜ë³µ)
        for step in range(future_steps):
            step_start_time = time.time()  # í˜„ì¬ ìŠ¤í… ì‹œì‘ ì‹œê°„
            # ë‹¤ìŒ ì˜ˆì¸¡ ì‹œì  ê³„ì‚°
            next_date = last_date + time_delta * (step + 1)
            
            # ì‹œê°„ ì •ë³´ ì¶”ì¶œ (íƒœì–‘ê´‘ ë°œì „ì€ ì‹œê°„ëŒ€ê°€ ì¤‘ìš”)
            hour = next_date.hour
            minute = next_date.minute
            
            # ğŸ”¥ ì•™ìƒë¸” ì˜ˆì¸¡: ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡í•˜ì—¬ í‰ê·  (ì•ˆì •ì„± í–¥ìƒ)
            ensemble_predictions = []
            
            for _ in range(n_ensemble):
                # ë…¸ì´ì¦ˆ ì¶”ê°€ (ì…ë ¥ ë°ì´í„°ì— ì‘ì€ ë³€ë™ ì¶”ê°€)
                noisy_sequence = current_sequence + np.random.normal(0, 0.05, current_sequence.shape)
                
                # LSTM ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜: (batch_size=1, seq_len, features)
                input_data = noisy_sequence.reshape(1, seq_len, len(study_columns_list))
                
                # ğŸ® GPUì—ì„œ ëª¨ë¸ ì˜ˆì¸¡ (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
                # verbose=0: ì˜ˆì¸¡ ì§„í–‰ ìƒí™© ì¶œë ¥ ì•ˆ í•¨
                pred_scaled = model.predict(input_data, verbose=0)
                ensemble_predictions.append(pred_scaled[0, 0])
            
            # ì•™ìƒë¸” í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°
            avg_pred_scaled = np.mean(ensemble_predictions)
            pred_std = np.std(ensemble_predictions)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            distance_penalty = 1.0 - (step / future_steps) * 0.3
            ensemble_uncertainty = min(pred_std / 0.1, 1.0)
            confidence = distance_penalty * (1.0 - ensemble_uncertainty)
            confidence = max(0.0, min(1.0, confidence))
            
            # ì˜ˆì¸¡ê°’ ì—­ì •ê·œí™”
            mean_values = scaler.mean_.copy()
            mean_values[target_idx] = avg_pred_scaled
            pred_value = scaler.inverse_transform([mean_values])[0, target_idx]
            
            # ğŸ”¥ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ë¬¼ë¦¬ì  ì œì•½ ì ìš©
            if 18 <= hour or hour < 6:
                pred_value = max(0, pred_value * 0.1)  # ì•¼ê°„
            else:
                pred_value = max(0, pred_value)  # ì£¼ê°„
            
            # ê²°ê³¼ ì €ì¥
            future_predictions.append(pred_value)
            future_dates.append(next_date)
            prediction_confidence.append(confidence)
            
            # ğŸ”¥ ë‹¤ìŒ ì‹œí€€ìŠ¤ ì¤€ë¹„
            new_point = current_sequence[-1].copy()
            new_point[target_idx] = avg_pred_scaled
            
            time_factor = np.sin(2 * np.pi * hour / 24)
            for i in range(len(new_point)):
                if i != target_idx:
                    new_point[i] += np.random.normal(0, 0.02) * time_factor
            
            current_sequence = np.vstack([current_sequence[1:], new_point])
            
            # í˜„ì¬ ìŠ¤í… ì™„ë£Œ ì‹œê°„ ê¸°ë¡
            step_elapsed = time.time() - step_start_time
            prediction_times.append(step_elapsed)
            
            # ì§„í–‰ìƒí™© í‘œì‹œ (ì„±ëŠ¥ ì •ë³´ í¬í•¨)
            if (step + 1) % 10 == 0 or step == future_steps - 1:
                avg_time_per_step = sum(prediction_times) / len(prediction_times)
                print(f"   â³ ì§„í–‰: {step + 1}/{future_steps} ìŠ¤í… ì™„ë£Œ "
                      f"(í‰ê·  {avg_time_per_step*1000:.1f}ms/ìŠ¤í…)")
        
        # ====================================================================
        # ì˜ˆì¸¡ ì™„ë£Œ ì‹œê°„ ê³„ì‚° ë° ì„±ëŠ¥ í†µê³„
        # ====================================================================
        elapsed_time = time.time() - start_time
        avg_step_time = sum(prediction_times) / len(prediction_times) if prediction_times else 0
        min_step_time = min(prediction_times) if prediction_times else 0
        max_step_time = max(prediction_times) if prediction_times else 0
        
        # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
        print(f"\nâœ… ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"ğŸ“Š ì„±ëŠ¥ í†µê³„:")
        print(f"   - ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
        print(f"   - í‰ê·  ìŠ¤í… ì‹œê°„: {avg_step_time*1000:.2f}ms")
        print(f"   - ìµœì†Œ ìŠ¤í… ì‹œê°„: {min_step_time*1000:.2f}ms")
        print(f"   - ìµœëŒ€ ìŠ¤í… ì‹œê°„: {max_step_time*1000:.2f}ms")
        print(f"   - ì²˜ë¦¬ëŸ‰: {future_steps/elapsed_time:.2f} ìŠ¤í…/ì´ˆ")
        
        if gpu_available:
            print(f"   ğŸ® GPU ê°€ì† í™œì„±í™”")
        else:
            print(f"   ğŸ’» CPU ëª¨ë“œ")
            print(f"   ğŸ’¡ GPU ì‚¬ìš© ì‹œ ì•½ 5-20ë°° ë¹ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # ê²°ê³¼ êµ¬ì„±
        future_result = {
            "model_name": config['modelName'],
            "target_column": targetColumn,
            "prediction_type": "future_improved",
            "base_date": last_date.isoformat(),
            "sequence_length": seq_len,
            "future_steps": future_steps,
            "prediction_interval": pred_days,
            "gpu_used": gpu_available,
            "performance": {
                "total_time_seconds": round(elapsed_time, 3),
                "average_step_time_ms": round(avg_step_time * 1000, 2),
                "min_step_time_ms": round(min_step_time * 1000, 2),
                "max_step_time_ms": round(max_step_time * 1000, 2),
                "throughput_steps_per_sec": round(future_steps / elapsed_time, 2)
            },
            "predictions": []
        }
        
        # ê° ìŠ¤í…ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        for i, (date, pred, conf) in enumerate(zip(future_dates, future_predictions, prediction_confidence)):
            future_result["predictions"].append({
                "step": i + 1,
                "date": date.isoformat(),
                "predicted_value": convert_to_serializable(pred),
                "confidence": convert_to_serializable(conf),
                "hour": date.hour,
                "is_daytime": 6 <= date.hour < 18
            })
        
        # í†µê³„ ì •ë³´ ì¶”ê°€
        future_result["statistics"] = {
            "min_predicted": convert_to_serializable(np.min(future_predictions)),
            "max_predicted": convert_to_serializable(np.max(future_predictions)),
            "mean_predicted": convert_to_serializable(np.mean(future_predictions)),
            "std_predicted": convert_to_serializable(np.std(future_predictions)),
            "avg_confidence": convert_to_serializable(np.mean(prediction_confidence))
        }
        
        return future_result
        
    except Exception as e:
        print(f"âŒ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# ============================================================================
# ê°œì„ ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
# ============================================================================
def print_future_predictions_improved(result):
    """
    ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    
    Parameters:
    -----------
    result : dict
        predict_future_improved() í•¨ìˆ˜ì˜ ë°˜í™˜ê°’
    """
    predictions = result.get('predictions', [])
    performance = result.get('performance', {})
    
    # í—¤ë” ì¶œë ¥
    print(f"\nğŸ”® ê°œì„ ëœ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ê²°ê³¼:")
    print(f"   ê¸°ì¤€ ì‹œì : {result['base_date'][:19]}")
    print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {result.get('sequence_length', 'N/A')}ê°œ")
    print(f"   ì´ ì˜ˆì¸¡ ìŠ¤í…: {result['future_steps']}ê°œ")
    
    # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
    print(f"\nâš¡ ì„±ëŠ¥ ì •ë³´:")
    print(f"   ì‹¤í–‰ í™˜ê²½: {'ğŸ® GPU' if result.get('gpu_used', False) else 'ğŸ’» CPU'}")
    print(f"   ì´ ì†Œìš” ì‹œê°„: {performance.get('total_time_seconds', 0):.3f}ì´ˆ")
    print(f"   í‰ê·  ìŠ¤í… ì‹œê°„: {performance.get('average_step_time_ms', 0):.2f}ms")
    print(f"   ì²˜ë¦¬ ì†ë„: {performance.get('throughput_steps_per_sec', 0):.2f} ìŠ¤í…/ì´ˆ")
    
    # GPU ì‚¬ìš© ì‹œ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ ì •ë³´
    if not result.get('gpu_used', False):
        estimated_gpu_time = performance.get('total_time_seconds', 0) / 10  # ì•½ 10ë°° ë¹ ë¥¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
        print(f"\n   ğŸ’¡ GPU ì‚¬ìš© ì‹œ ì˜ˆìƒ ì‹œê°„: ~{estimated_gpu_time:.3f}ì´ˆ (ì•½ 5-20ë°° í–¥ìƒ)")
    
    print("\n" + "=" * 80)
    print(f"{'ìŠ¤í…':>6} {'ì˜ˆì¸¡ ë‚ ì§œ':<20} {'ì‹œê°„':>6} {'ì˜ˆì¸¡ê°’':>12} {'ì£¼ì•¼':>10}")
    print("=" * 80)
    
    # ê° ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
    for pred in predictions:
        date_str = pred['date'][:19]
        hour = pred.get('hour', 0)
        is_day = "â˜€ï¸ ì£¼ê°„" if pred.get('is_daytime', False) else "ğŸŒ™ ì•¼ê°„"
        
        print(f"{pred['step']:>6} {date_str:<20} {hour:>6}ì‹œ "
              f"{pred['predicted_value']:>12.4f} {is_day:>10}")
    
    print("=" * 80)
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = result.get('statistics', {})
    
    print(f"\nğŸ“Š ì˜ˆì¸¡ê°’ í†µê³„:")
    print(f"   ìµœì†Ÿê°’: {stats.get('min_predicted', 0):.4f}")
    print(f"   ìµœëŒ“ê°’: {stats.get('max_predicted', 0):.4f}")
    print(f"   í‰ê· ê°’: {stats.get('mean_predicted', 0):.4f}")
    print(f"   í‘œì¤€í¸ì°¨: {stats.get('std_predicted', 0):.4f}")

# ============================================================================
# ğŸ”¥ ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ì €ì¥
# ============================================================================
def save_predictions_to_db(prediction_result, target_table="solar_generation_forecast"):
    """
    ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ PostgreSQL DBì— ì €ì¥
    time_pointê°€ ì¤‘ë³µë˜ë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì‹ ê·œ ë°ì´í„° INSERT
    
    Parameters:
    -----------
    prediction_result : dict
        predict_future_improved() í•¨ìˆ˜ì˜ ë°˜í™˜ê°’
    target_table : str
        ì €ì¥í•  í…Œì´ë¸”ëª… (ê¸°ë³¸ê°’: 'solar_generation_forecast')
        
    Returns:
    --------
    tuple : (ì„±ê³µ ê±´ìˆ˜, ì‹¤íŒ¨ ê±´ìˆ˜)
    """
    if prediction_result is None:
        print("âŒ ì €ì¥í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0, 0
    
    try:
        engine = get_db_engine()
        predictions = prediction_result.get('predictions', [])
        
        if not predictions:
            print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return 0, 0
        
        print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ DB ì €ì¥ ì‹œì‘...")
        print(f"   - ëŒ€ìƒ í…Œì´ë¸”: carbontwin.{target_table}")
        print(f"   - ì €ì¥í•  ë°ì´í„°: {len(predictions)}ê±´")
        
        success_count = 0
        fail_count = 0
        
        with engine.connect() as conn:
            trans = conn.begin()
            
            try:
                for pred in predictions:
                    time_point = pred['date']
                    forecast_value = pred['predicted_value']
                    
                    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                    delete_query = text(f"""
                    DELETE FROM carbontwin.{target_table}
                    WHERE time_point = :time_point
                    """)
                    
                    conn.execute(delete_query, {"time_point": time_point})
                    
                    # ìƒˆë¡œìš´ ë°ì´í„° INSERT
                    insert_query = text(f"""
                    INSERT INTO carbontwin.{target_table} 
                        (time_point, forecast_solar_kwh, reg_dt)
                    VALUES 
                        (:time_point, :forecast_value, CURRENT_TIMESTAMP)
                    """)
                    
                    conn.execute(
                        insert_query,
                        {
                            "time_point": time_point,
                            "forecast_value": forecast_value
                        }
                    )
                    
                    success_count += 1
                    
                    if success_count % 10 == 0:
                        print(f"   â³ ì§„í–‰: {success_count}/{len(predictions)} ê±´ ì €ì¥ ì™„ë£Œ")
                
                trans.commit()
                
                print(f"âœ… DB ì €ì¥ ì™„ë£Œ!")
                print(f"   - ì„±ê³µ: {success_count}ê±´")
                print(f"   - ì‹¤íŒ¨: {fail_count}ê±´")
                
            except Exception as e:
                trans.rollback()
                print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¡¤ë°±ë¨): {str(e)}")
                import traceback
                traceback.print_exc()
                return success_count, len(predictions) - success_count
        
        return success_count, fail_count
        
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return 0, len(predictions)

# ============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================
def main(model_name=None, tablename=None, save_to_db=True):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì „ì²´ ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    
    Parameters:
    -----------
    model_name : str, optional
        ì‚¬ìš©í•  ëª¨ë¸ëª… (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    tablename : str, optional
        ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ í…Œì´ë¸”ëª… (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    save_to_db : bool, optional
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ì €ì¥í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
    Returns:
    --------
    dict : ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼
    """
    print("=" * 70)
    print("ğŸ”® ê°œì„ ëœ LSTM ëª¨ë¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (DB ì €ì¥ + GPU ì§€ì›)")
    print("=" * 70)
    
    # 1. ëª¨ë¸ëª…
    if model_name is None:
        model_name = "solar-hybrid-seq-2-test-20251017-test-no"
    
    # 2. ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ì„¤ì • ë¡œë“œ
    model, scaler, config = load_trained_model(model_name)
    
    # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ
    if model is None:
        print("\nğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
        if os.path.exists(model_path):
            models = [f.replace('.h5', '') for f in os.listdir(model_path) if f.endswith('.h5')]
            if models:
                for i, m in enumerate(models, 1):
                    print(f"   {i}. {m}")
            else:
                print("   (ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤)")
        return None
    
    # 3. í…Œì´ë¸”ëª… ì„¤ì •
    if tablename is None:
        tablename = "lstm_input_15m_new"
    print(f"\nğŸ“Š ì‚¬ìš©í•  í…Œì´ë¸”: {tablename}")
    
    # 4. DBì—ì„œ ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    new_data = load_new_data(
        tablename,
        config['dateColumn'],
        config['studyColumns'],
        start_date=None,
        end_date=None
    )
    
    if new_data is None or new_data.empty:
        print("âŒ ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # 5. ì‹¤ì œ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì‹¤í–‰
    print(f"\n{'='*70}")
    
    seq_len = int(config.get('r_seqLen', 60))
    auto_future_steps = 672
    
    print(f"ğŸ”® ê°œì„ ëœ ì‹¤ì œ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ìˆ˜í–‰")
    print(f"   - ëª¨ë¸ ì‹œí€€ìŠ¤ ê¸¸ì´: {seq_len}")
    print(f"   - ì˜ˆì¸¡í•  ë¯¸ë˜ ìŠ¤í…: {auto_future_steps}ê°œ")
    
    future_result = None
    
    try:
        # ë¯¸ë˜ê°’ ì˜ˆì¸¡ ìˆ˜í–‰ (GPU ê°€ì† ì§€ì›)
        future_result = predict_future_improved(
            model, scaler, config, new_data, auto_future_steps
        )
        
        if future_result:
            # ì˜ˆì¸¡ ê²°ê³¼ ì½˜ì†” ì¶œë ¥
            print_future_predictions_improved(future_result)
            
            # DBì— ì €ì¥
            if save_to_db:
                success, fail = save_predictions_to_db(future_result)
                
                if success > 0:
                    print(f"\nâœ… ì´ {success}ê±´ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                if fail > 0:
                    print(f"âš ï¸  {fail}ê±´ì˜ ì €ì¥ ì‹¤íŒ¨")
        else:
            print("âŒ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨")
        
    except Exception as e:
        print(f"âŒ ë¯¸ë˜ê°’ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # 6. ì™„ë£Œ ë©”ì‹œì§€
    print(f"\n{'='*70}")
    print("ğŸ‰ ì˜ˆì¸¡ ì™„ë£Œ!")
    print("="*70)
    
    return future_result

# ============================================================================
# í”„ë¡œê·¸ë¨ ì‹œì‘ì 
# ============================================================================
if __name__ == "__main__":
    """
    ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ main() í•¨ìˆ˜ í˜¸ì¶œ
    
    ì‚¬ìš©ë²•:
        # DB ì €ì¥ í™œì„±í™” (ê¸°ë³¸)
        python lstm_predict.py
        
        # DB ì €ì¥ ë¹„í™œì„±í™” (í…ŒìŠ¤íŠ¸ìš©)
        # main(save_to_db=False) í˜•íƒœë¡œ ì½”ë“œ ìˆ˜ì • í•„ìš”
        
    GPU ì‚¬ìš© ìš”êµ¬ì‚¬í•­:
        1. NVIDIA GPU ë“œë¼ì´ë²„ ì„¤ì¹˜
        2. CUDA Toolkit 11.8 ë˜ëŠ” 12.x ì„¤ì¹˜
        3. cuDNN 8.x ì„¤ì¹˜
        4. TensorFlow GPU: pip install tensorflow[and-cuda]
    """
    try:
        # DB ì €ì¥ í™œì„±í™” ìƒíƒœë¡œ ì‹¤í–‰
        main(
            model_name="solar-hybrid-seq-2-test-20251017-test-no",      # ëª¨ë¸ëª…
            tablename="lstm_input_15m_new", # ì…ë ¥ í…Œì´ë¸”ëª…
            save_to_db=True            # DB ì €ì¥ í™œì„±í™”
        )
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()